---
{
    "name": "DAVIS-NUIUIED",
    "aliases": [],
    "year": 2022,
    "modality": [
        "Vision"
    ],
    "sensors": [
        "DAVIS346"
    ],
    "other_sensors": [],
    "category": "Domain Specific Application",
    "subcategory": [
        "Underwater Imaging"
    ],
    "task": "Underwater Imaging",
    "dataset_properties": {
        "available_online": true,
        "has_real_data": true,
        "has_simulated_data": false,
        "has_ground_truth": false,
        "has_frames": true,
        "has_biases": false,
        "distribution_methods": [
            "Figshare"
        ],
        "file_formats": [
            "ROSbag"
        ],
        "availability_comment": "",
        "dataset_links": [
            {
                "name": "Figshare",
                "url": "https://figshare.com/articles/dataset/DAVIS-NUIUIED_A_DAVIS-based_non-uniform_illumination_underwater_image_enhancement_dataset_/19719898",
                "format": "ROSbag",
                "available": true
            }
        ],
        "size_gb": 1.18,
        "size_type": "Compressed"
    },
    "paper": {
        "title": "Non-uniform illumination underwater image enhancement via events and frame fusion",
        "doi": "10.1364/AO.463099",
        "authors": [
            "Xiuwen Bi",
            "Pengfei Wang",
            "Tao Wu",
            "Fusheng Zha",
            "Peng Xu"
        ],
        "abstract": "Absorption and scattering by aqueous media can attenuate light and cause underwater optical imagery difficulty. Artificial light sources are usually used to aid deep-sea imaging. Due to the limited dynamic range of standard cameras, artificial light sources often cause underwater images to be underexposed or overexposed. By contrast, event cameras have a high dynamic range and high temporal resolution but cannot provide frames with rich color characteristics. In this paper, we exploit the complementarity of the two types of cameras to propose an efficient yet simple method for image enhancement of uneven underwater illumination, which can generate enhanced images containing better scene details and colors similar to standard frames. Additionally, we create a dataset recorded by the Dynamic and Active-pixel Vision Sensor that includes both event streams and frames, enabling testing of the proposed method and frame-based image enhancement methods. The experimental results conducted on our dataset with qualitative and quantitative measures demonstrate that the proposed method outperforms the compared enhancement algorithms.",
        "open_access": false
    },
    "citation_counts": [
        {
            "source": "crossref",
            "count": 3,
            "updated": "2025-06-03T12:19:52.178155"
        },
        {
            "source": "scholar",
            "count": 4,
            "updated": "2025-06-03T12:19:50.992144"
        }
    ],
    "links": [
        {
            "type": "paper",
            "url": "https://opg.optica.org/ao/abstract.cfm?uri=ao-61-29-8826"
        }
    ],
    "full_name": "The DAVIS Non-Uniform Illumination Underwater Image Enhancement Dataset (DAVIS-NUIUIED)",
    "additional_metadata": {
        "num_recordings": "10"
    },
    "bibtex": {
        "pages": "8826--8832",
        "keywords": "Image enhancement, Image metrics, Imaging techniques, Light sources, Scattering media, Underwater imaging",
        "note": "Publisher: Optica Publishing Group",
        "year": 2022,
        "month": "oct",
        "author": "Bi, Xiuwen and Wang, Pengfei and Wu, Tao and Zha, Fusheng and Xu, Peng",
        "journal": "Appl. Opt.",
        "number": "29",
        "doi": "10.1364/AO.463099",
        "url": "https://opg.optica.org/ao/abstract.cfm?URI=ao-61-29-8826",
        "volume": "61",
        "title": "Non-uniform illumination underwater image enhancement via events and frame fusion",
        "type": "article",
        "key": "Bi2022"
    },
    "referenced_papers": [
        {
            "doi": "10.1109/ISCAS.2015.7168731",
            "source": "crossref"
        },
        {
            "doi": "10.1007/s11263-019-01209-w",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ACCESS.2020.3002593",
            "source": "crossref"
        },
        {
            "doi": "10.1109/LSP.2018.2812861",
            "source": "crossref"
        },
        {
            "doi": "10.1016/S0734-189X(87)80186-X",
            "source": "crossref"
        },
        {
            "doi": "10.1109/76.915354",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TCE.2007.4429280",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TCE.2007.381734",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TIP.2009.2021548",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TIP.2016.2612882",
            "source": "crossref"
        },
        {
            "doi": "10.1007/s00371-021-02281-5",
            "source": "crossref"
        },
        {
            "doi": "10.1016/j.dsp.2022.103532",
            "source": "crossref"
        },
        {
            "doi": "10.1109/83.597272",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TIP.2013.2261309",
            "source": "crossref"
        },
        {
            "doi": "10.1016/j.sigpro.2016.05.031",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TIP.2016.2639450",
            "source": "crossref"
        },
        {
            "doi": "10.1007/978-3-319-64698-5_4",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TIP.2018.2810539",
            "source": "crossref"
        },
        {
            "doi": "10.1016/j.image.2021.116141Get",
            "source": "crossref"
        },
        {
            "doi": "10.1007/s11554-020-00950-7",
            "source": "crossref"
        },
        {
            "doi": "10.1109/LSP.2020.3008347",
            "source": "crossref"
        },
        {
            "doi": "10.1145/3394171.3413925",
            "source": "crossref"
        },
        {
            "doi": "10.1145/3072959.3073592",
            "source": "crossref"
        },
        {
            "doi": "10.1145/3343031.3350926",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TIP.2019.2910412",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2007.914337",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2014.2342715",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TPAMI.2019.2963386",
            "source": "crossref"
        },
        {
            "doi": "10.6084/m9.figshare.19719898",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TIP.2017.2759252",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TIP.2017.2745202",
            "source": "crossref"
        },
        {
            "doi": "10.1109/26.477498",
            "source": "crossref"
        },
        {
            "doi": "10.1109/LSP.2012.2227726",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JOE.2015.2469915",
            "source": "crossref"
        },
        {
            "title": "Machine vision using combined frame-based and event-based vision sensor",
            "source": "crossref"
        },
        {
            "title": "A weighted variational model for simultaneous reflectance and illumination estimation",
            "source": "crossref"
        },
        {
            "title": "A new image contrast enhancement algorithm using exposure fusion framework",
            "source": "crossref"
        },
        {
            "title": "Fast enhancement for non-uniform illumination images using light-weight CNNs",
            "source": "crossref"
        },
        {
            "title": "Learning to see in the dark",
            "source": "crossref"
        },
        {
            "title": "Kindling the darkness: a practical low-light image enhancer",
            "source": "crossref"
        },
        {
            "title": "Underexposed photo enhancement using deep illumination estimation",
            "source": "crossref"
        },
        {
            "title": "Zero-reference deep curve estimation for low-light image enhancement",
            "source": "crossref"
        },
        {
            "title": "Zero-shot restoration of underexposed images via robust retinexdecomposition",
            "source": "crossref"
        },
        {
            "title": "Learning multi-scale photo exposure correction",
            "source": "crossref"
        },
        {
            "title": "Asynchronous, photometric feature tracking using events and frames",
            "source": "crossref"
        },
        {
            "title": "Continuous-time intensity estimation using event cameras",
            "source": "crossref"
        },
        {
            "title": "Reducing the sim-to-real gap for event cameras",
            "source": "crossref"
        },
        {
            "title": "Events-to-video: bringing modern computer vision to event cameras",
            "source": "crossref"
        },
        {
            "title": "U-Net: convolutional networks for biomedical image segmentation",
            "source": "crossref"
        },
        {
            "title": "ESIM: an open event camera simulator",
            "source": "crossref"
        },
        {
            "title": "A no-reference perceptual blur metric based on complex edge analysis",
            "source": "crossref"
        }
    ]
}
---

### Dataset Structure

- Dataset contains data from 10 different scenes.
