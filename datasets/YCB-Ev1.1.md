---
{
    "name": "YCB-Ev1.1",
    "aliases": [],
    "year": 2025,
    "modalities": [
        "Vision"
    ],
    "sensors": [
        "ATIS"
    ],
    "other_sensors": [
        "Realsense D435"
    ],
    "category": "Depth, Stereo, and 3D Reconstruction",
    "tags": [
        "Pose Estimation"
    ],
    "description": "Object Pose Estimation Dataset",
    "dataset_properties": {
        "available_online": true,
        "has_real_data": true,
        "has_simulated_data": false,
        "has_ground_truth": true,
        "has_frames": true,
        "has_biases": true,
        "distribution_methods": [
            "HuggingFace"
        ],
        "file_formats": [
            "Other"
        ],
        "availability_comment": "",
        "dataset_links": [
            {
                "name": "HuggingFace",
                "url": "https://huggingface.co/datasets/paroj/ycbev",
                "format": "Other",
                "available": true
            }
        ],
        "size_gb": 28.3,
        "size_type": "Compressed"
    },
    "paper": {
        "title": "YCB-Ev 1.1: Event-Vision Dataset for\u00a06DoF Object Pose Estimation",
        "doi": "10.1007/978-3-031-91569-7_1",
        "authors": [
            "Pavel Rojtberg",
            "Thomas P\u00f6llabauer"
        ],
        "abstract": "Our work introduces the YCB-Ev dataset, which contains synchronized RGB-D frames and event data that enables evaluating 6DoF object pose estimation algorithms using these modalities. This dataset provides ground truth 6DoF object poses for the same 21 YCB objects [1] that were used in the YCB-Video (YCB-V) dataset [25], allowing for cross-dataset algorithm performance evaluation. The dataset consists of 21 synchronized event and RGB-D sequences, totalling 13,851 frames (7 min and 43 s of event data). Notably, 12 of these sequences feature the same object arrangement as the YCB-V subset used in the BOP challenge [21]. Ground truth poses are generated by detecting objects in the RGB-D frames, interpolating the poses to align with the event timestamps, and then transferring them to the event coordinate frame using extrinsic calibration. Our dataset is the first to provide ground truth 6DoF pose data for event streams. Furthermore, we evaluate the generalization capabilities of two state-of-the-art algorithms, which were pre-trained for the BOP challenge, using our novel YCB-V sequences. The dataset is publicly available at https://github.com/paroj/ycbev.",
        "open_access": false
    },
    "citation_counts": [
        {
            "source": "crossref",
            "count": 0,
            "updated": "2025-09-13T13:07:57.459433"
        },
        {
            "source": "scholar",
            "count": 3,
            "updated": "2025-09-13T13:08:00.181912"
        }
    ],
    "links": [
        {
            "type": "preprint",
            "url": "https://arxiv.org/abs/2309.08482"
        },
        {
            "type": "github_page",
            "url": "https://github.com/paroj/ycbev"
        }
    ],
    "full_name": "",
    "additional_metadata": {},
    "referenced_papers": [
        {
            "doi": "10.1177/0278364917700714",
            "source": "crossref"
        },
        {
            "doi": "10.17487/RFC8478",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TPAMI.2020.3008413",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR42600.2020.00364",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICRA40945.2020.9197426",
            "source": "crossref"
        },
        {
            "doi": "10.1007/978-3-030-58520-4_34",
            "source": "crossref"
        },
        {
            "doi": "10.1109/IROS.2014.6942940",
            "source": "crossref"
        },
        {
            "doi": "10.3389/fnins.2015.00437",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ISMAR.2018.00026",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2016.445",
            "source": "crossref"
        },
        {
            "doi": "10.3389/fnins.2015.00481",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2018.00186",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR52688.2022.00673",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPRW59228.2023.00279",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2011.5995347",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPRW.2018.00275",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR52733.2024.01956",
            "source": "crossref"
        },
        {
            "doi": "10.15607/RSS.2018.XIV.019",
            "source": "crossref"
        }
    ],
    "bibtex": {
        "pages": "1\u201313",
        "year": 2025,
        "author": "Rojtberg, Pavel and P\u00f6llabauer, Thomas",
        "publisher": "Springer Nature Switzerland",
        "booktitle": "Computer Vision \u2013 ECCV 2024 Workshops",
        "doi": "10.1007/978-3-031-91569-7_1",
        "url": "http://dx.doi.org/10.1007/978-3-031-91569-7_1",
        "issn": "1611-3349",
        "isbn": "9783031915697",
        "title": "YCB-Ev 1.1: Event-Vision Dataset for\u00a06DoF Object Pose Estimation",
        "type": "book",
        "key": "Rojtberg_2025"
    }
}
---

# Dataset Description

The YCB-Ev dataset contains synchronized RGB-D frames and event data that enables evaluating 6DoF object pose estimation algorithms using these modalities. This dataset provides ground truth 6DoF object poses for the same 21 YCB objects that were used in the YCB-Video (YCB-V) dataset, allowing for cross-dataset algorithm performance evaluation. The dataset consists of 21 synchronized event and RGB-D sequences, totalling 13,851 frames (7 minutes and 43 seconds of event data). Notably, 12 of these sequences feature the same object arrangement as the YCB-V subset used in the BOP challenge.

Ground truth poses are generated by detecting objects in the RGB-D frames, interpolating the poses to align with the event timestamps, and then transferring them to the event coordinate frame using extrinsic calibration

# Dataset Structure

| File Name               | Size     |
|------------------------|----------|
| 01_events.int32.zst    | 950 MB   |
| 02_events.int32.zst    | 1.34 GB  |
| 03_events.int32.zst    | 1.07 GB  |
| 04_events.int32.zst    | 1.09 GB  |
| 05_events.int32.zst    | 976 MB   |
| 06_events.int32.zst    | 1.04 GB  |
| 07_events.int32.zst    | 1.08 GB  |
| 08_events.int32.zst    | 1.16 GB  |
| 09_events.int32.zst    | 1.09 GB  |
| 10_events.int32.zst    | 1.18 GB  |
| 11_events.int32.zst    | 1.21 GB  |
| 12_events.int32.zst    | 1.33 GB  |
| 13_events.int32.zst    | 1.37 GB  |
| 14_events.int32.zst    | 1.20 GB  |
| 15_events.int32.zst    | 1.46 GB  |
| 16_events.int32.zst    | 1.14 GB  |
| 17_events.int32.zst    | 751 MB   |
| 18_events.int32.zst    | 742 MB   |
| 19_events.int32.zst    | 1.24 GB  |
| 20_events.int32.zst    | 839 MB   |
| 21_events.int32.zst    | 1.03 GB  |
| ycbev_all_real.zst     | 11.3 GB  |
| ycbv_models.zip        | 2.78 MB  |