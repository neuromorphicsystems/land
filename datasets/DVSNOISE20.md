---
{
    "name": "DVSNOISE20",
    "aliases": [],
    "year": 2020,
    "modalities": [
        "Vision"
    ],
    "sensors": [
        "DAVIS346"
    ],
    "other_sensors": [],
    "category": "Filtering and De-noising",
    "tags": [
        "De-noising"
    ],
    "description": "Event Labelling and Denoising",
    "dataset_properties": {
        "available_online": false,
        "has_real_data": true,
        "has_simulated_data": false,
        "has_ground_truth": false,
        "has_frames": false,
        "has_biases": false,
        "distribution_methods": [
            "Google Drive"
        ],
        "file_formats": [
            "aedat"
        ],
        "availability_comment": "",
        "dataset_links": [
            {
                "name": "Google Drive",
                "url": "https://drive.usercontent.google.com/download?id=1omYF3ecjrQVhfpgEe6nm9FgfLo4Yax3_&export=download&authuser=0",
                "format": "aedat",
                "available": false
            }
        ],
        "size_gb": 7.4,
        "size_type": "Compressed"
    },
    "paper": {
        "title": "Event Probability Mask (EPM) and Event Denoising Convolutional Neural Network (EDnCNN) for Neuromorphic Cameras",
        "doi": "10.1109/CVPR42600.2020.00177",
        "authors": [
            "R. Wes Baldwin",
            "Mohammed Almatrafi",
            "Vijayan Asari",
            "Keigo Hirakawa"
        ],
        "abstract": "This paper presents a novel method for labeling realworld neuromorphic camera sensor data by calculating the likelihood of generating an event at each pixel within a short time window, which we refer to as \u201cevent probability mask\u201d or EPM. Its applications include (i) objective benchmarking of event denoising performance, (ii) training convolutional neural networks for noise removal called \u201cevent denoising convolutional neural network\u201d (EDnCNN), and (iii) estimating internal neuromorphic camera parameters. We provide the \ufb01rst dataset (DVSNOISE20) of real-world labeled neuromorphic camera events for noise removal.",
        "open_access": false
    },
    "citation_counts": [
        {
            "source": "crossref",
            "count": 65,
            "updated": "2025-06-15T10:57:22.666270"
        },
        {
            "source": "scholar",
            "count": 98,
            "updated": "2025-06-15T10:57:22.509578"
        }
    ],
    "links": [
        {
            "type": "preprint",
            "url": "https://arxiv.org/abs/2003.08282"
        },
        {
            "type": "paper",
            "url": "https://ieeexplore.ieee.org/document/9156496"
        },
        {
            "type": "project_page",
            "url": "https://sites.google.com/a/udayton.edu/issl/software/dataset"
        },
        {
            "type": "github_page",
            "url": "https://github.com/bald6354/edncnn"
        }
    ],
    "full_name": "",
    "additional_metadata": {
        "num_recordings": "16",
        "recording_duration": "16 seconds",
        "stereo": false
    },
    "bibtex": {
        "pages": "1698--1707",
        "year": 2020,
        "month": "jun",
        "author": "Baldwin, R. Wes and Almatrafi, Mohammed and Asari, Vijayan and Hirakawa, Keigo",
        "publisher": "IEEE",
        "booktitle": "2020 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})",
        "urldate": "2024-04-13",
        "language": "en",
        "doi": "10.1109/CVPR42600.2020.00177",
        "url": "https://ieeexplore.ieee.org/document/9156496/",
        "isbn": "978-1-72817-168-5",
        "copyright": "https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html",
        "title": "Event {Probability} {Mask} ({EPM}) and {Event} {Denoising} {Convolutional} {Neural} {Network} ({EDnCNN}) for {Neuromorphic} {Cameras}",
        "address": "Seattle, WA, USA",
        "type": "inproceedings",
        "key": "baldwin_event_2020"
    },
    "referenced_papers": [
        {
            "doi": "10.3390/s18020333",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2019.00398",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TIM.2019.2919354",
            "source": "crossref"
        },
        {
            "doi": "10.5244/C.31.33",
            "source": "crossref"
        },
        {
            "doi": "10.1109/IROS.2018.8593805",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2018.00568",
            "source": "crossref"
        },
        {
            "doi": "10.1109/LRA.2016.2645143",
            "source": "crossref"
        },
        {
            "doi": "10.3389/fnins.2018.00118",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TPAMI.2015.2392947",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2007.914337",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ISCAS.2015.7168735",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICCV.2019.00573",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TETC.2017.2788865",
            "source": "crossref"
        },
        {
            "doi": "10.1016/0004-3702(81)90024-2",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TPAMI.2016.2574707",
            "source": "crossref"
        },
        {
            "doi": "10.3389/fnins.2015.00046",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICCV.2019.00058",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2014.2342715",
            "source": "crossref"
        },
        {
            "doi": "10.3389/fnins.2016.00176",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICRA.2019.8794255",
            "source": "crossref"
        },
        {
            "doi": "10.1109/BIOROB.2016.7523449",
            "source": "crossref"
        },
        {
            "doi": "10.23919/ICIF.2018.8455718",
            "source": "crossref"
        },
        {
            "doi": "10.1109/BIOROB.2016.7523452",
            "source": "crossref"
        },
        {
            "doi": "10.1007/978-3-030-27272-2_35",
            "source": "crossref"
        },
        {
            "doi": "10.1109/LRA.2018.2849882",
            "source": "crossref"
        },
        {
            "doi": "10.1109/WACV.2016.7477561",
            "source": "crossref"
        },
        {
            "doi": "10.3390/s18124122",
            "source": "crossref"
        },
        {
            "doi": "10.1016/j.neunet.2011.11.001",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TNNLS.2013.2273537",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2019.00108",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICIP.2017.8296630",
            "source": "crossref"
        },
        {
            "doi": "10.1007/978-3-642-39402-7_14",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICCV.2019.00734",
            "source": "crossref"
        },
        {
            "doi": "10.15607/RSS.2018.XIV.062",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2019.00985",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPRW.2019.00215",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2018.00186",
            "source": "crossref"
        },
        {
            "title": "Esim: an open event camera simulator",
            "source": "crossref"
        },
        {
            "title": "Davis camera optical flow",
            "source": "crossref"
        },
        {
            "title": "Eklt: Asynchronous photometric feature tracking using events and frames",
            "source": "crossref"
        },
        {
            "title": "Evaluation of event-based algorithms for optical flow with ground-truth from inertial measurement sensor",
            "source": "crossref"
        },
        {
            "title": "Learning event-based height from plane and parallax",
            "source": "crossref"
        },
        {
            "title": "Approaches for astrometry using event-based sensors",
            "source": "crossref"
        },
        {
            "title": "Frame-free dynamic digital vision",
            "source": "crossref"
        },
        {
            "title": "Event-net: Asynchronous recursive event processing",
            "source": "crossref"
        }
    ]
}
---

### Dataset Structure

This dataset is designed to evaluate event denoising algorithm performance against real sensor data. Data was collected using a DAVIS346 neuromorphic camera. Movement of the camera was restricted by a gimbal, and the IMU was calibrated before each collection. Only stationary scenes were selected, avoiding saturation and severe noise in the APS.

The dataset contains 16 indoor and outdoor scenes of noisy, real-world data. Each scene was captured three times for â‰ˆ16 seconds, giving 48 total sequences with a wide range of motions.

Adapted from https://sites.google.com/a/udayton.edu/issl/software/dataset
