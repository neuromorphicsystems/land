---
{
    "name": "Steffen2024",
    "aliases": [],
    "year": 2024,
    "modality": [
        "Vision"
    ],
    "sensors": [
        "Prophesee Gen3"
    ],
    "other_sensors": [],
    "category": "Human-centric Recordings",
    "tags": [
        "Gesture Recognition"
    ],
    "description": "Gesture Recognition",
    "dataset_properties": {
        "available_online": false,
        "has_real_data": true,
        "has_simulated_data": false,
        "has_ground_truth": false,
        "has_frames": true,
        "has_biases": false,
        "distribution_methods": [],
        "file_formats": [
            "ROSbag"
        ],
        "availability_comment": "",
        "dataset_links": []
    },
    "paper": {
        "title": "Efficient Gesture Recognition on Spiking Convolutional Networks Through Sensor Fusion of Event-Based and Depth Data",
        "doi": "10.1109/ICRA57147.2024.10610824",
        "authors": [
            "Lea Steffen",
            "Thomas Trapp",
            "Arne Roennau",
            "R\u00fcdiger Dillmann"
        ],
        "abstract": "As intelligent systems become increasingly important in our daily lives, new ways of interaction are needed. Classical user interfaces pose issues for the physically impaired and are partially not practical or convenient. Gesture recognition is an alternative, but often not reactive enough when conventional cameras are used. This work proposes a Spiking Convolutional Neural Network, processing event- and depth data for gesture recognition. The network is simulated using the open-source neuromorphic computing framework LAVA for offline training and evaluation on an embedded system. For the evaluation three open source data sets are used. Since these do not represent the applied bi-modality, a new data set with synchronized event- and depth data was recorded. The results show the viability of temporal encoding on depth information and modality fusion, even on differently encoded data, to be beneficial to network performance and generalization capabilities.",
        "open_access": false
    },
    "citation_counts": [
        {
            "source": "crossref",
            "count": 0,
            "updated": "2025-06-02T14:52:54.397580"
        }
    ],
    "links": [
        {
            "type": "preprint",
            "url": "https://arxiv.org/abs/2401.17064"
        },
        {
            "type": "paper",
            "url": "https://ieeexplore.ieee.org/document/10610824"
        }
    ],
    "full_name": "",
    "additional_metadata": {
        "num_subjects": "5",
        "num_recordings": "300"
    },
    "bibtex": {
        "pages": "345--352",
        "year": 2024,
        "month": "may",
        "author": "Steffen, Lea and Trapp, Thomas and Roennau, Arne and Dillmann, R\u00fcdiger",
        "publisher": "IEEE",
        "booktitle": "2024 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})",
        "urldate": "2024-12-15",
        "language": "en",
        "doi": "10.1109/ICRA57147.2024.10610824",
        "url": "https://ieeexplore.ieee.org/document/10610824/",
        "isbn": "9798350384574",
        "copyright": "https://doi.org/10.15223/policy-029",
        "title": "Efficient {Gesture} {Recognition} on {Spiking} {Convolutional} {Networks} {Through} {Sensor} {Fusion} of {Event}-{Based} and {Depth} {Data}",
        "address": "Yokohama, Japan",
        "type": "inproceedings",
        "key": "Steffen2024"
    },
    "referenced_papers": [
        {
            "doi": "10.1016/S0893-6080(97)00011-7",
            "source": "crossref"
        },
        {
            "doi": "10.1007/978-3-540-92910-9_10",
            "source": "crossref"
        },
        {
            "doi": "10.3389/fnins.2021.638474",
            "source": "crossref"
        },
        {
            "doi": "10.1038/nn1177",
            "source": "crossref"
        },
        {
            "doi": "10.1109/MSP.2019.2931595",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ACCESS.2020.2990416",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ISCAS.2012.6272144",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2017.781",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICASSP.2019.8683606",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ISCAS45731.2020.9181247",
            "source": "crossref"
        },
        {
            "doi": "10.1109/MM.2018.112130359",
            "source": "crossref"
        },
        {
            "doi": "10.1109/WACV.2019.00199",
            "source": "crossref"
        },
        {
            "doi": "10.3389/fnins.2020.00637",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICIP.2015.7350781",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICASSP.2016.7472170",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2010.2085952",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICAR46387.2019.8981569",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ROBIO.2018.8665314",
            "source": "crossref"
        },
        {
            "doi": "10.1109/IROS47612.2022.9981453",
            "source": "crossref"
        },
        {
            "title": "Event-based Vision: A Survey",
            "source": "crossref"
        },
        {
            "title": "A Theoretical Analysis of Neuronal Variability",
            "source": "crossref"
        },
        {
            "title": "Sparser spiking activity can be better: Feature Refine-and-Mask spiking neural network for event-based visual recognition",
            "source": "crossref"
        },
        {
            "title": "First spikes in ensembles of human tactile afferents code complex spatial fingertip events",
            "source": "crossref"
        },
        {
            "title": "Learning representations by back-propagating errors",
            "source": "crossref"
        },
        {
            "title": "Towards Biologically Plausible Deep Learning",
            "source": "crossref"
        },
        {
            "title": "SLAYER: Spike Layer Error Reassignment in Time",
            "source": "crossref"
        },
        {
            "title": "Online Few-shot Gesture Learning on a Neuromorphic Processor",
            "source": "crossref"
        },
        {
            "title": "Bridging the Gap between Events and Frames through Unsupervised Domain Adaptation",
            "source": "crossref"
        },
        {
            "title": "Lava Software Framework",
            "source": "crossref"
        },
        {
            "title": "DVS128 Gesture Dataset - IBM Research",
            "source": "crossref"
        }
    ]
}
---

### Dataset Structure

- Contains data from 5
- Contains 300 recordings in total

### Comparison Table

| **dataset**       | **modality**    | **device**         | **datatype** | **resolution**          | **# actions** | **subjects** | **trials** |
| ----------------- | --------------- | ------------------ | ------------ | ----------------------- | ------------- | ------------ | ---------- |
| \[[DVS-GESTURE]\] | events          | DVS128             | aedat3.1     | 128 × 128               | 10 + 1        | 29           | 5          |
| UTD-MHAD          | depth           | Kinect             | MAT file     | 320 × 240               | 27            | 8            | 4          |
| UTD-Kinect2       | depth           | Kinect 2           | MAT file     | 512 × 424               | 10            | 6            | 5          |
| \[[Steffen2024]\] | event and depth | ATIS and RealSense | ROSbag       | 480 × 360 and 640 × 480 | 30            | 2            | 5          |
