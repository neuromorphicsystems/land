---
{
    "name": "EHPT-XC",
    "aliases": [],
    "year": 2024.0,
    "modalities": [
        "Vision"
    ],
    "sensors": [
        "Prophesee Gen4"
    ],
    "other_sensors": [
        "BFS-U3-16S2C-CS"
    ],
    "category": "Human-centric Recordings",
    "tags": [
        "Pose Estimation",
        "Low Light",
        "Beamsplitters"
    ],
    "description": "Human Pose Estimation in Extreme Conditions",
    "dataset_properties": {
        "available_online": false,
        "has_real_data": true,
        "has_simulated_data": false,
        "has_ground_truth": true,
        "has_frames": true,
        "has_biases": false,
        "distribution_methods": [],
        "file_formats": [],
        "availability_comment": "Requires a user agreement form to be downloaded, signed, and returned. Handwritten signatures are required.",
        "dataset_links": [],
        "size_gb": 0.0,
        "size_type": "Compressed"
    },
    "paper": {
        "title": "A benchmark dataset for event-guided human pose estimation and tracking in extreme conditions",
        "doi": "",
        "authors": [
            "Hoonhee Cho",
            "Taewoo Kim",
            "Yuhwan Jeong",
            "Kuk-Jin Yoon"
        ],
        "abstract": "Multi-person pose estimation and tracking have been actively researched by the computer vision community due to their practical applicability. However, existing human pose estimation and tracking datasets have only been successful in typical scenarios, such as those without motion blur or with well-lit conditions. These RGB-based datasets are limited to learning under extreme motion blur situations or poor lighting conditions, making them inherently vulnerable to such scenarios.As a promising solution, bio-inspired event cameras exhibit robustness in extreme scenarios due to their high dynamic range and micro-second level temporal resolution. Therefore, in this paper, we introduce a new hybrid dataset encompassing both RGB and event data for human pose estimation and tracking in two extreme scenarios: low-light and motion blur environments. The proposed Event-guided Human Pose Estimation and Tracking in eXtreme Conditions (EHPT-XC) dataset covers cases of motion blur caused by dynamic objects and low-light conditions individually as well as both simultaneously. With EHPT-XC, we aim to inspire researchers to tackle pose estimation and tracking in extreme conditions by leveraging the advantageous of the event camera. Project pages are available at https://github.com/Chohoonhee/EHPT-XC.",
        "open_access": false
    },
    "citation_counts": [],
    "links": [
        {
            "type": "paper",
            "url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/f304e427cfe6bb762fe1bf18516c8a87-Abstract-Datasets_and_Benchmarks_Track.html"
        },
        {
            "type": "github_page",
            "url": "https://github.com/Chohoonhee/EHPT-XC"
        }
    ],
    "full_name": "Event-guided Human Pose Estimation and Tracking in eXtreme Conditions (EHPTXC)",
    "additional_metadata": {
        "num_males": "61",
        "num_females": "21",
        "num_subjects": "82"
    },
    "bibtex": {
        "year": 2024,
        "booktitle": "The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track",
        "author": "Cho, Hoonhee and Kim, Taewoo and Jeong, Yuhwan and Yoon, Kuk-Jin",
        "title": "A Benchmark Dataset for Event-Guided Human Pose Estimation and Tracking in Extreme Conditions",
        "type": "inproceedings",
        "key": "cho2024benchmark"
    }
}
---

# Dataset Description