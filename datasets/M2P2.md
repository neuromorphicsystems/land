---
{
    "name": "M2P2",
    "aliases": [],
    "year": 2024,
    "modalities": [
        "Vision"
    ],
    "sensors": [
        "Prophesee Gen4"
    ],
    "other_sensors": [
        " Xenics Ceres T 1280",
        "FLIR Blackfly S",
        "Yahboom 10-DoF IMU",
        "Ouster OS1-128"
    ],
    "category": "Robotic and Moving Vehicle Datasets",
    "tags": [
        "Low Light",
        "Object Detection",
        "Driving Dataset",
        "Autonomous Driving"
    ],
    "description": "Low-light Passive Perception Datset",
    "dataset_properties": {
        "available_online": true,
        "has_real_data": true,
        "has_simulated_data": false,
        "has_ground_truth": true,
        "has_frames": true,
        "has_biases": true,
        "distribution_methods": [
            "Direct Download"
        ],
        "file_formats": [
            "ROSbag"
        ],
        "availability_comment": "",
        "dataset_links": [
            {
                "name": "Direct Download",
                "url": "https://dataverse.orc.gmu.edu/dataset.xhtml?persistentId=doi:10.13021/orc2020/SP577T",
                "format": "ROSbag",
                "available": true
            }
        ],
        "size_gb": 1138.63,
        "size_type": "Compressed"
    },
    "paper": {
        "title": "M2P2: A Multi-Modal Passive Perception Dataset for Off-Road Mobility in Extreme Low-Light Conditions",
        "doi": "10.48550/arXiv.2410.01105",
        "authors": [
            "Aniket Datar",
            "Anuj Pokhrel",
            "Mohammad Nazeri",
            "Madhan B. Rao",
            "Chenhui Pan",
            "Yufan Zhang",
            "Andre Harrison",
            "Maggie Wigness",
            "Philip R. Osteen",
            "Jinwei Ye",
            "Xuesu Xiao"
        ],
        "abstract": "Long-duration, off-road, autonomous missions require robots to continuously perceive their surroundings regardless of the ambient lighting conditions. Most existing autonomy systems heavily rely on active sensing, e.g., LiDAR, RADAR, and Time-of-Flight sensors, or use (stereo) visible light imaging sensors, e.g., color cameras, to perceive environment geometry and semantics. In scenarios where fully passive perception is required and lighting conditions are degraded to an extent that visible light cameras fail to perceive, most downstream mobility tasks such as obstacle avoidance become impossible. To address such a challenge, this paper presents a Multi-Modal Passive Perception dataset, M2P2, to enable off-road mobility in low-light to no-light conditions. We design a multi-modal sensor suite including thermal, event, and stereo RGB cameras, GPS, two Inertia Measurement Units (IMUs), as well as a high-resolution LiDAR for ground truth, with a novel multi-sensor calibration procedure that can efficiently transform multi-modal perceptual streams into a common coordinate system. Our 10-hour, 32 km dataset also includes mobility data such as robot odometry and actions and covers well-lit, low-light, and no-light conditions, along with paved, on-trail, and off-trail terrain. Our results demonstrate that off-road mobility is possible through only passive perception in extreme low-light conditions using end-to-end learning and classical planning. The project website can be found at https://cs.gmu.edu/~xiao/Research/M2P2/",
        "open_access": false
    },
    "citation_counts": [
        {
            "source": "scholar",
            "count": 1,
            "updated": "2025-09-13T13:17:36.386222"
        }
    ],
    "links": [
        {
            "type": "project_page",
            "url": "https://cs.gmu.edu/~xiao/Research/M2P2/"
        },
        {
            "type": "preprint",
            "url": "https://arxiv.org/abs/2410.01105"
        },
        {
            "type": "github_page",
            "url": "https://github.com/RobotiXX/M2P2/"
        }
    ],
    "full_name": "",
    "additional_metadata": {
        "total_duration": "10 hours",
        "total_distance": "32 km"
    },
    "bibtex": {
        "copyright": "Creative Commons Attribution 4.0 International",
        "year": 2024,
        "publisher": "arXiv",
        "title": "M2P2: A Multi-Modal Passive Perception Dataset for Off-Road Mobility in Extreme Low-Light Conditions",
        "keywords": "Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences",
        "author": "Datar, Aniket and Pokhrel, Anuj and Nazeri, Mohammad and Rao, Madhan B. and Pan, Chenhui and Zhang, Yufan and Harrison, Andre and Wigness, Maggie and Osteen, Philip R. and Ye, Jinwei and Xiao, Xuesu",
        "url": "https://arxiv.org/abs/2410.01105",
        "doi": "10.48550/ARXIV.2410.01105",
        "type": "misc",
        "key": "https://doi.org/10.48550/arxiv.2410.01105"
    }
}
---

# Dataset Description

- Total Compressed Size: 1138.63 GB
- Total Distance: >32 km
- Total Time: ~10.15 hours
- Environments: Paved trails, non-paved off-road paths, and unprepared off-trail areas
- Lighting Conditions: 20 lx to complete darkness (0 lx)

The M2P2 dataset encompasses over 10 hours of data collected across various challenging terrain conditions. The data are gathered with the sensor suite mounted on a Clearpath Husky A200 robot. The dataset includes sequences from a diverse range of environments, progressing from fully prepared paved trails to non-paved off-road paths, and ultimately to unprepared off-trail environments within densely forested areas featuring thick vegetation and narrow passages. To capture a comprehensive range of lighting conditions, data collection is conducted at dusk, with luminosity levels varying from 20 lx to complete darkness (0 lx). This approach ensures the dataset's applicability to both well-lit and no-light scenarios, addressing the challenges of navigation in varying environmental conditions.