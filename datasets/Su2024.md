---
{
    "name": "Su2024",
    "aliases": [],
    "year": 2024,
    "modality": [
        "Vision"
    ],
    "sensors": [
        "Prophesee Gen4"
    ],
    "other_sensors": [],
    "category": "Domain Specific Application",
    "subcategory": [
        "Optical Communication"
    ],
    "task": "Optical Communication with an Event-based Sensor",
    "dataset_properties": {
        "available_online": true,
        "has_real_data": true,
        "has_simulated_data": false,
        "has_ground_truth": true,
        "has_frames": false,
        "has_biases": false,
        "distribution_methods": [
            "Google Drive"
        ],
        "file_formats": [
            "ROSbag"
        ],
        "availability_comment": "",
        "dataset_links": [
            {
                "name": "Google Drive",
                "url": "https://drive.google.com/file/d/1AN-MyGDBzKnodQiOJwfY-3UyuNw-aiyB/view?usp=sharing",
                "format": "ROSbag",
                "available": true
            }
        ],
        "size_gb": 4.1,
        "size_type": "Compressed"
    },
    "paper": {
        "title": "Motion-Aware Optical Camera Communication With Event Cameras",
        "doi": "10.1109/LRA.2024.3517292",
        "authors": [
            "Hang Su",
            "Ling Gao",
            "Tao Liu",
            "Laurent Kneip"
        ],
        "abstract": "As the ubiquity of smart mobile devices continues to rise, Optical Camera Communication systems have gained more attention as a solution for efficient and private data streaming. This system utilizes optical cameras to receive data from digital screens via visible light. Despite their promise, most of them are hindered by dynamic factors such as screen refreshing and rapid camera motion. CMOS cameras, often serving as the receivers, suffer from limited frame rates and motion-induced image blur, which degrade overall performance. To address these challenges, this letter unveils a novel system that utilizes event cameras. We introduce a dynamic visual marker and design event-based tracking algorithms to achieve fast localization and data streaming. Remarkably, the event camera's unique capabilities mitigate issues related to screen refresh rates and camera motion, enabling a high throughput of up to 114 Kbps in static conditions, and a 1cm localization accuracy with 1% bit error rate under various camera motions.",
        "open_access": false
    },
    "citation_counts": [
        {
            "source": "crossref",
            "count": 0,
            "updated": "2025-07-07T07:54:03.335989"
        },
        {
            "source": "scholar",
            "count": 2,
            "updated": "2025-07-07T07:54:03.086705"
        }
    ],
    "links": [
        {
            "type": "preprint",
            "url": "https://arxiv.org/pdf/2412.00816"
        },
        {
            "type": "paper",
            "url": "https://ieeexplore.ieee.org/document/10797688"
        },
        {
            "type": "github_page",
            "url": "https://github.com/suhang99/EventOCC"
        }
    ],
    "full_name": "",
    "additional_metadata": {
        "stereo": false
    },
    "bibtex": {
        "doi": "10.1109/LRA.2024.3517292",
        "keywords": "Cameras;Streaming media;Optical receivers;Location awareness;Tracking;Event detection;Dynamics;Payloads;Optical imaging;Optical distortion;Localization;visual tracking;automation technologies for smart cities",
        "pages": "1385-1392",
        "number": "2",
        "volume": "10",
        "year": 2025,
        "title": "Motion-Aware Optical Camera Communication With Event Cameras",
        "journal": "IEEE Robotics and Automation Letters",
        "author": "Su, Hang and Gao, Ling and Liu, Tao and Kneip, Laurent",
        "type": "article",
        "key": "10797688"
    },
    "referenced_papers": [
        {
            "doi": "10.1109/COMST.2019.2913348",
            "source": "crossref"
        },
        {
            "doi": "10.1016/j.phycom.2019.100900",
            "source": "crossref"
        },
        {
            "doi": "10.1145/2307636.2307645",
            "source": "crossref"
        },
        {
            "doi": "10.1145/1859995.1860012",
            "source": "crossref"
        },
        {
            "doi": "10.1109/infocom.2016.7524512",
            "source": "crossref"
        },
        {
            "doi": "10.1145/2742647.2742667",
            "source": "crossref"
        },
        {
            "doi": "10.1145/2500423.2500437",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TPAMI.2020.3008413",
            "source": "crossref"
        },
        {
            "doi": "10.1109/COMST.2015.2476474",
            "source": "crossref"
        },
        {
            "doi": "10.1109/WACV.2012.6162992",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICCW.2019.8756795",
            "source": "crossref"
        },
        {
            "doi": "10.1109/LRA.2023.3304905",
            "source": "crossref"
        },
        {
            "doi": "10.1109/IROS.2016.7759610",
            "source": "crossref"
        },
        {
            "doi": "10.5244/C.31.33",
            "source": "crossref"
        },
        {
            "doi": "10.1109/LRA.2018.2849882",
            "source": "crossref"
        },
        {
            "doi": "10.1109/LRA.2019.2893427",
            "source": "crossref"
        },
        {
            "doi": "10.1109/LRA.2022.3187266",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICRA.2017.7989517",
            "source": "crossref"
        },
        {
            "doi": "10.1109/LRA.2024.3350982",
            "source": "crossref"
        },
        {
            "doi": "10.1109/IROS.2014.6942940",
            "source": "crossref"
        },
        {
            "doi": "10.1109/EBCCSP.2016.7605244",
            "source": "crossref"
        },
        {
            "doi": "10.3389/fnbot.2018.00004",
            "source": "crossref"
        },
        {
            "doi": "10.1109/IROS51168.2021.9636824",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICCV51070.2023.00739",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR52733.2024.01383",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ACCESS.2021.3058423",
            "source": "crossref"
        },
        {
            "doi": "10.1117/12.2679683",
            "source": "crossref"
        },
        {
            "doi": "10.3390/s21041137",
            "source": "crossref"
        },
        {
            "doi": "10.1109/IROS.2013.6696456",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TASE.2020.3045880",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSEN.2020.2990752",
            "source": "crossref"
        },
        {
            "doi": "10.1109/IROS40897.2019.8967787",
            "source": "crossref"
        },
        {
            "doi": "10.1016/j.patcog.2014.01.005",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TNNLS.2013.2273537",
            "source": "crossref"
        },
        {
            "doi": "10.1109/9780470546345",
            "source": "crossref"
        },
        {
            "doi": "10.1109/LRA.2022.3186770",
            "source": "crossref"
        },
        {
            "doi": "10.1109/34.88573",
            "source": "crossref"
        },
        {
            "title": "Linking vision and multi-agent communication through visible light communication using event cameras",
            "source": "crossref"
        },
        {
            "title": "HASTE: Multi-hypothesis asynchronous speeded-up tracking of events",
            "source": "crossref"
        }
    ]
}
---


### Dataset Structure