---
{
    "name": "NFPP Dataset",
    "aliases": [],
    "year": 2020,
    "modality": [
        "Vision"
    ],
    "sensors": [
        "DAVIS346"
    ],
    "other_sensors": [],
    "category": "Depth, Stereo, and 3D Reconstruction",
    "subcategory": [
        "3D Reconstruction"
    ],
    "task": "3D reconstruction for Fringe Projection Profilometry (FFP)",
    "dataset_properties": {
        "available_online": true,
        "has_real_data": true,
        "has_simulated_data": false,
        "has_ground_truth": false,
        "has_frames": false,
        "has_biases": false,
        "distribution_methods": [
            "Google Drive"
        ],
        "file_formats": [
            "CSV"
        ],
        "availability_comment": "",
        "dataset_links": [
            {
                "name": "Google Drive",
                "url": "https://drive.google.com/drive/folders/1DChe45OtZhLeuBitztfafJeo-j0zl9eQ",
                "format": "CSV",
                "available": true
            }
        ],
        "size_gb": 0.086,
        "size_type": "Compressed"
    },
    "paper": {
        "title": "Neuromorphic Fringe Projection Profilometry",
        "doi": "10.1109/LSP.2020.3016251",
        "authors": [
            "Ashish Rao Mangalore",
            "Chandra Sekhar Seelamantula",
            "Chetan Singh Thakur"
        ],
        "abstract": "We address the problem of 3-D reconstruction using neuromorphic cameras (also known as event-driven cameras), which are a new class of vision-inspired imaging devices. Neuromorphic cameras are becoming increasingly popular for solving image processing and computer vision problems as they have signi\ufb01cantly lower data rates than conventional frame-based cameras. We develop a neuromorphic-camera-based Fringe Projection Pro\ufb01lometry (FPP) system. We use the Dynamic Vision Sensor (DVS) in the DAVIS346 neuromorphic camera for acquiring measurements. Neuromorphic FPP is faster than a single-line-scanning method. Also, unlike frame-based FPP, the ef\ufb01cacy of the proposed method is not limited by the background while acquiring measurements. The working principle of the DVS also allows one to ef\ufb01ciently handle shadows thereby preventing ambiguities during 2-D phase unwrapping.",
        "open_access": false
    },
    "citation_counts": [
        {
            "source": "crossref",
            "count": 22,
            "updated": "2025-07-02T14:25:52.714687"
        },
        {
            "source": "scholar",
            "count": 32,
            "updated": "2025-07-02T14:25:52.402323"
        }
    ],
    "links": [
        {
            "type": "paper",
            "url": "https://ieeexplore.ieee.org/document/9166707"
        },
        {
            "type": "github_page",
            "url": "https://github.com/ashishrao7/NFPP?tab=readme-ov-file"
        }
    ],
    "full_name": "Neuromorphic Fringe Projection Profilometry (NFFP)",
    "additional_metadata": {
        "stereo": false
    },
    "bibtex": {
        "pages": "1510--1514",
        "year": 2020,
        "author": "Mangalore, Ashish Rao and Seelamantula, Chandra Sekhar and Thakur, Chetan Singh",
        "journal": "IEEE Signal Processing Letters",
        "urldate": "2024-04-13",
        "language": "en",
        "doi": "10.1109/LSP.2020.3016251",
        "url": "https://ieeexplore.ieee.org/document/9166707/",
        "issn": "1070-9908, 1558-2361",
        "copyright": "https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html",
        "volume": "27",
        "title": "Neuromorphic {Fringe} {Projection} {Profilometry}",
        "type": "article",
        "key": "mangalore_neuromorphic_2020"
    },
    "referenced_papers": [
        {
            "doi": "10.1109/2945.817351",
            "source": "crossref"
        },
        {
            "doi": "10.1364/AO.41.005896",
            "source": "crossref"
        },
        {
            "doi": "10.1364/AO.41.007437",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TVCG.2012.34",
            "source": "crossref"
        },
        {
            "doi": "10.1109/34.888718",
            "source": "crossref"
        },
        {
            "doi": "10.1109/IROS.2014.6942940",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ISCAS.2019.8702581",
            "source": "crossref"
        },
        {
            "doi": "10.1002/widm.1310",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TPAMI.2020.3008413",
            "source": "crossref"
        },
        {
            "doi": "10.1007/978-3-030-01246-5_15",
            "source": "crossref"
        },
        {
            "doi": "10.1007/s11263-017-1050-6",
            "source": "crossref"
        },
        {
            "doi": "10.1007/978-3-319-46466-4_21",
            "source": "crossref"
        },
        {
            "doi": "10.3389/fnins.2013.00275",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICCPHOT.2015.7168370",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TCSI.2004.835026",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ARVLSI.1999.756038",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2019.01258",
            "source": "crossref"
        },
        {
            "doi": "10.1007/978-1-4615-2724-4_2",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2010.2085952",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2019.00398",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ISSCC.2001.912560",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2019.01049",
            "source": "crossref"
        },
        {
            "doi": "10.1007/978-3-030-30642-7_28",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2014.2342715",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2019.00108",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2007.914337",
            "source": "crossref"
        },
        {
            "doi": "10.1016/j.acha.2013.02.002",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TSP.2020.2967182",
            "source": "crossref"
        },
        {
            "doi": "10.1137/S0036144501386986",
            "source": "crossref"
        },
        {
            "doi": "10.1109/SampTA45681.2019.9030899",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICASSP.2019.8682626",
            "source": "crossref"
        },
        {
            "doi": "10.1364/AO.23.003105",
            "source": "crossref"
        },
        {
            "title": "MeshLab: An open-source mesh processing tool",
            "source": "crossref"
        },
        {
            "title": "The jAER library",
            "source": "crossref"
        },
        {
            "title": "A 64&#x00D7;64 AER logarithmic temporal derivative silicon retina",
            "source": "crossref"
        },
        {
            "title": "The libcaer library",
            "source": "crossref"
        },
        {
            "title": "Python code for neuromorphic fringe projection, profilometry",
            "source": "crossref"
        },
        {
            "title": "Event-based structured light for depth reconstruction using frequency tagged light patterns",
            "source": "crossref"
        },
        {
            "title": "EV-SegNet: Semantic segmentation for event-based cameras",
            "source": "crossref"
        }
    ]
}
---


### Dataset Structure