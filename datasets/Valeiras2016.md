---
{
    "name": "Valeiras2016",
    "aliases": [],
    "year": 2016,
    "modality": [
        "Vision"
    ],
    "sensors": [
        "ATIS"
    ],
    "other_sensors": [],
    "category": "Depth, Stereo, and 3D Reconstruction",
    "subcategory": [
        "3D Reconstruction",
        "3D Pose Estimation"
    ],
    "task": "3D Pose Estimation",
    "dataset_properties": {
        "available_online": false,
        "has_real_data": true,
        "has_simulated_data": false,
        "has_ground_truth": true,
        "has_frames": false,
        "has_biases": false,
        "distribution_methods": [
            "Google Drive"
        ],
        "file_formats": [
            "Binary"
        ],
        "availability_comment": "Dataset link no longer works",
        "dataset_links": [
            {
                "name": "Google Drive",
                "url": "https://drive.google.com/folderview?id=0B5gzfP0R1VEFNS1PZ0xKU3F5dG8&usp=sharing.",
                "format": "Binary",
                "available": false
            }
        ]
    },
    "paper": {
        "title": "Neuromorphic Event-Based 3D Pose Estimation",
        "doi": "10.3389/fnins.2015.00522",
        "authors": [
            "David Reverter Valeiras",
            "Garrick Orchard",
            "Sio-Hoi Ieng",
            "Ryad B. Benosman"
        ],
        "abstract": "Pose estimation is a fundamental step in many artificial vision tasks. It consists of estimating the 3D pose of an object with respect to a camera from the object's 2D projection. Current state of the art implementations operate on images. These implementations are computationally expensive, especially for real-time applications. Scenes with fast dynamics exceeding 30\u201360 Hz can rarely be processed in real-time using conventional hardware. This paper presents a new method for event-based 3D object pose estimation, making full use of the high temporal resolution (1 \u03bcs) of asynchronous visual events output from a single neuromorphic camera. Given an initial estimate of the pose, each incoming event is used to update the pose by combining both 3D and 2D criteria. We show that the asynchronous high temporal resolution of the neuromorphic camera allows us to solve the problem in an incremental manner, achieving real-time performance at an update rate of several hundreds kHz on a conventional laptop. We show that the high temporal resolution of neuromorphic cameras is a key feature for performing accurate pose estimation. Experiments are provided showing the performance of the algorithm on real data, including fast moving objects, occlusions, and cases where the neuromorphic camera and the object are both in motion.",
        "open_access": true
    },
    "citation_counts": [
        {
            "source": "crossref",
            "count": 16,
            "updated": "2025-07-02T14:20:18.978738"
        },
        {
            "source": "scholar",
            "count": 54,
            "updated": "2025-07-02T14:20:18.667969"
        }
    ],
    "links": [
        {
            "type": "paper",
            "url": "https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2015.00522/"
        }
    ],
    "full_name": "",
    "additional_metadata": {
        "stereo": false
    },
    "bibtex": {
        "issn": "1662-453X",
        "doi": "10.3389/fnins.2015.00522",
        "url": "https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2015.00522",
        "year": 2016,
        "volume": "Volume 9 - 2015",
        "journal": "Frontiers in Neuroscience",
        "title": "Neuromorphic Event-Based 3D Pose Estimation",
        "author": "Reverter Valeiras, David  and Orchard, Garrick  and Ieng, Sio-Hoi  and Benosman, Ryad B. ",
        "type": "article",
        "key": "10.3389/fnins.2015.00522"
    },
    "referenced_papers": [
        {
            "doi": "10.1145/2001269.2001293",
            "source": "crossref"
        },
        {
            "doi": "10.1016/j.neunet.2011.11.001",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TNN.2011.2167239",
            "source": "crossref"
        },
        {
            "doi": "10.1109/82.842110",
            "source": "crossref"
        },
        {
            "doi": "10.1201/b10688",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ISCAS.2010.5537149",
            "source": "crossref"
        },
        {
            "doi": "10.1007/BF01450852",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TPAMI.2002.1017620",
            "source": "crossref"
        },
        {
            "doi": "10.1145/358669.358692",
            "source": "crossref"
        },
        {
            "doi": "10.1007/978-1-4612-2664-2_7",
            "source": "crossref"
        },
        {
            "doi": "10.1007/s10851-009-0161-2",
            "source": "crossref"
        },
        {
            "doi": "10.1201/9781420040692.ch15",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TRO.2010.2061290",
            "source": "crossref"
        },
        {
            "doi": "10.1109/IWAR.1999.803809",
            "source": "crossref"
        },
        {
            "doi": "10.1023/A:1007927317325",
            "source": "crossref"
        },
        {
            "doi": "10.1561/0600000001",
            "source": "crossref"
        },
        {
            "doi": "10.1007/s11263-008-0152-6",
            "source": "crossref"
        },
        {
            "doi": "10.1109/34.862199",
            "source": "crossref"
        },
        {
            "doi": "10.1006/cviu.1996.0037",
            "source": "crossref"
        },
        {
            "doi": "10.1109/tpami.2015.2392947",
            "source": "crossref"
        },
        {
            "doi": "10.1017/CBO9780511804120",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2010.2085952",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TNNLS.2015.2401834",
            "source": "crossref"
        },
        {
            "doi": "10.1145/325165.325242",
            "source": "crossref"
        },
        {
            "doi": "10.1007/s11263-007-0107-3",
            "source": "crossref"
        },
        {
            "doi": "10.20870/IJVR.2010.9.2.2767",
            "source": "crossref"
        },
        {
            "title": "Building rome in a day",
            "source": "crossref"
        },
        {
            "title": "Asynchronous frameless event-based optical flow",
            "source": "crossref"
        },
        {
            "title": "Asynchronous event-based hebbian epipolar geometry",
            "source": "crossref"
        },
        {
            "title": "Point-to-point connectivity between neuromorphic chips using address-events",
            "source": "crossref"
        },
        {
            "title": "Activity-driven, event-based vision sensors",
            "source": "crossref"
        },
        {
            "title": "Model-based object pose in 25 lines of code",
            "source": "crossref"
        },
        {
            "title": "Real-time visual tracking of complex structures",
            "source": "crossref"
        },
        {
            "title": "Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography",
            "source": "crossref"
        },
        {
            "title": "Hidden-line removal",
            "source": "crossref"
        },
        {
            "title": "Tracking with rigid models",
            "source": "crossref"
        },
        {
            "title": "Metrics for 3d rotations: Comparison and analysis",
            "source": "crossref"
        },
        {
            "title": "Visual servoing: theory and applications",
            "source": "crossref"
        },
        {
            "title": "A kalman-filter-based method for pose estimation in visual servoing",
            "source": "crossref"
        },
        {
            "title": "Marker tracking and hmd calibration for a video-based augmented reality conferencing system",
            "source": "crossref"
        },
        {
            "title": "3d pose estimation by directly matching polyhedral models to gray value gradients",
            "source": "crossref"
        },
        {
            "title": "Monocular model-based 3d tracking of rigid objects: A survey",
            "source": "crossref"
        },
        {
            "title": "Accurate non-iterative O(n) solution to the PnP problem",
            "source": "crossref"
        },
        {
            "title": "EPnP: an accurate O(n) solution to the PnP problem",
            "source": "crossref"
        },
        {
            "title": "Fast and globally convergent pose estimation from video images",
            "source": "crossref"
        },
        {
            "title": "Iterative pose estimation using coplanar feature points",
            "source": "crossref"
        },
        {
            "title": "Hfirst: a temporal approach to object recognition",
            "source": "crossref"
        },
        {
            "title": "A QVGA 143 dB dynamic range frame-free PWM image sensor with lossless pixel-level video compression and time-domain CDS",
            "source": "crossref"
        },
        {
            "title": "An asynchronous neuromorphic event-driven visual part-based shape tracking",
            "source": "crossref"
        },
        {
            "title": "Animating rotation with quaternion curves",
            "source": "crossref"
        },
        {
            "title": "Modeling the world from internet photo collections",
            "source": "crossref"
        },
        {
            "title": "A survey of augmented reality technologies, applications and limitations",
            "source": "crossref"
        }
    ]
}
---

### Dataset Structure
