---
{
    "name": "Jiang2024b",
    "aliases": [],
    "year": 2024,
    "modalities": [
        "Vision"
    ],
    "sensors": [
        "DAVIS346"
    ],
    "other_sensors": [],
    "category": "Human-centric Recordings",
    "tags": [
        "Eye Tracking",
        "Gaze Tracking",
        "Blink Detection"
    ],
    "description": "Eye tracking",
    "dataset_properties": {
        "available_online": false,
        "has_real_data": true,
        "has_simulated_data": false,
        "has_ground_truth": true,
        "has_frames": false,
        "has_biases": false,
        "distribution_methods": [],
        "file_formats": [],
        "availability_comment": "Dataset available on request",
        "dataset_links": []
    },
    "paper": {
        "title": "Eye Tracking Based on Event Camera and Spiking Neural Network",
        "doi": "10.3390/electronics13142879",
        "authors": [
            "Yizhou Jiang",
            "Wenwei Wang",
            "Lei Yu",
            "Chu He"
        ],
        "abstract": "An event camera generates an event stream based on changes in brightness, retaining only the characteristics of moving objects, and addresses the high power consumption associated with using high-frame-rate cameras for high-speed eye-tracking tasks. However, the asynchronous incremental nature of event camera output has not been fully utilized, and there are also issues related to missing event datasets. Combining the temporal information encoding and state-preserving properties of a spiking neural network (SNN) with an event camera, a near-range eye-tracking algorithm is proposed as well as a novel event-based dataset for validation and evaluation. According to experimental results, the proposed solution outperforms artificial neural network (ANN) algorithms, while computational time remains only 12.5% of that of traditional SNN algorithms. Furthermore, the proposed algorithm allows for self-adjustment of time resolution, with a maximum achievable resolution of 0.081 ms, enhancing tracking stability while maintaining accuracy.",
        "open_access": true
    },
    "citation_counts": [
        {
            "source": "crossref",
            "count": 1,
            "updated": "2025-07-11T08:43:04.708145"
        },
        {
            "source": "scholar",
            "count": 6,
            "updated": "2025-07-11T08:43:04.341907"
        }
    ],
    "links": [
        {
            "type": "paper",
            "url": "https://www.mdpi.com/2079-9292/13/14/2879"
        }
    ],
    "full_name": "",
    "additional_metadata": {
        "num_subjects": "4",
        "num_male": "3",
        "num_female": "3",
        "stereo": false
    },
    "bibtex": {
        "pages": "2879",
        "year": 2024,
        "month": "jul",
        "author": "Jiang, Yizhou and Wang, Wenwei and Yu, Lei and He, Chu",
        "journal": "Electronics",
        "urldate": "2024-12-15",
        "number": "14",
        "language": "en",
        "doi": "10.3390/electronics13142879",
        "url": "https://www.mdpi.com/2079-9292/13/14/2879",
        "issn": "2079-9292",
        "copyright": "https://creativecommons.org/licenses/by/4.0/",
        "volume": "13",
        "title": "Eye {Tracking} {Based} on {Event} {Camera} and {Spiking} {Neural} {Network}",
        "type": "article",
        "key": "jiang_eye_2024"
    },
    "referenced_papers": [
        {
            "doi": "10.1212/WNL.0000000000012774",
            "source": "crossref"
        },
        {
            "doi": "10.1016/j.jad.2021.10.028",
            "source": "crossref"
        },
        {
            "doi": "10.1080/20008198.2021.1943188",
            "source": "crossref"
        },
        {
            "doi": "10.1007/s10055-022-00738-z",
            "source": "crossref"
        },
        {
            "doi": "10.1109/AICAS57966.2023.10168551",
            "source": "crossref"
        },
        {
            "doi": "10.1145/3491207",
            "source": "crossref"
        },
        {
            "doi": "10.1109/VR.2019.8797752",
            "source": "crossref"
        },
        {
            "doi": "10.3390/s20174935",
            "source": "crossref"
        },
        {
            "doi": "10.1109/BioCAS58349.2023.10389062",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TVCG.2021.3067784",
            "source": "crossref"
        },
        {
            "doi": "10.1109/WACV51458.2022.00399",
            "source": "crossref"
        },
        {
            "doi": "10.1145/3586182.3616657",
            "source": "crossref"
        },
        {
            "doi": "10.1109/VR51125.2022.00059",
            "source": "crossref"
        },
        {
            "doi": "10.1016/j.patcog.2022.108944",
            "source": "crossref"
        },
        {
            "doi": "10.1038/s41586-024-07409-w",
            "source": "crossref"
        },
        {
            "doi": "10.1016/j.jneumeth.2019.05.016",
            "source": "crossref"
        },
        {
            "doi": "10.1109/IADCC.2015.7154783",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ACCESS.2020.2980005",
            "source": "crossref"
        },
        {
            "doi": "10.1016/S0893-6080(97)00011-7",
            "source": "crossref"
        },
        {
            "doi": "10.1007/s11263-014-0788-3",
            "source": "crossref"
        },
        {
            "doi": "10.1109/MSP.2019.2931595",
            "source": "crossref"
        },
        {
            "doi": "10.3389/fnins.2016.00508",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TIP.2022.3228168",
            "source": "crossref"
        },
        {
            "doi": "10.3389/fnins.2023.1123698",
            "source": "crossref"
        },
        {
            "doi": "10.1007/978-3-030-86365-4",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR52688.2022.00358",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR52688.2022.00860",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPRW53098.2021.00144",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR42600.2020.00364",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICCV48922.2021.00266",
            "source": "crossref"
        },
        {
            "doi": "10.1162/089976603322362365",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2018.00935",
            "source": "crossref"
        },
        {
            "doi": "10.1007/s11042-021-11304-1",
            "source": "crossref"
        },
        {
            "doi": "10.1126/sciadv.adi1480",
            "source": "crossref"
        },
        {
            "title": "Association of Clinically Evident Eye Movement Abnormalities with Motor and Cognitive Features in Patients with Motor Neuron Disorders",
            "source": "crossref"
        },
        {
            "title": "A Combination of P300 and Eye Movement Data Improves the Accuracy of Auxiliary Diagnoses of Depression",
            "source": "crossref"
        },
        {
            "title": "Early Intervention with Eye Movement Desensitization and Reprocessing (EMDR) Therapy to Reduce the Severity of Post-Traumatic Stress Symptoms in Recent Rape Victims: A Randomized Controlled Trial",
            "source": "crossref"
        },
        {
            "title": "Eye Tracking in Virtual Reality: A Broad Review of Applications and Challenges",
            "source": "crossref"
        },
        {
            "title": "The Eye in Extended Reality: A Survey on Gaze Interaction and Eye Tracking in Head-worn Extended Reality",
            "source": "crossref"
        },
        {
            "title": "EV-Eye: Rethinking High-frequency Eye Tracking through the Lenses of Event Cameras",
            "source": "crossref"
        },
        {
            "title": "Event-Based Near-Eye Gaze Tracking Beyond 10,000 Hz",
            "source": "crossref"
        },
        {
            "title": "In the Eye of the Beholder: A Survey of Gaze Tracking Techniques",
            "source": "crossref"
        },
        {
            "title": "Low-latency automotive vision with event cameras",
            "source": "crossref"
        },
        {
            "title": "DeepVOG: Open-Source Pupil Segmentation and Gaze Estimation in Neuroscience Using Deep Learning",
            "source": "crossref"
        },
        {
            "title": "Real-Time Iris Tracking Using Deep Regression Networks for Robotic Ophthalmic Surgery",
            "source": "crossref"
        },
        {
            "title": "Networks of spiking neurons: The third generation of neural network models",
            "source": "crossref"
        },
        {
            "title": "Spiking Deep Convolutional Neural Networks for Energy-Efficient Object Recognition",
            "source": "crossref"
        },
        {
            "title": "Surrogate Gradient Learning in Spiking Neural Networks: Bringing the Power of Gradient-Based Optimization to Spiking Neural Networks",
            "source": "crossref"
        },
        {
            "title": "Spike-Based Motion Estimation for Object Tracking Through Bio-Inspired Unsupervised Learning",
            "source": "crossref"
        },
        {
            "title": "Self-Supervised Learning of Event-Based Optical Flow with Spiking Neural Networks",
            "source": "crossref"
        },
        {
            "title": "Deep Residual Learning in Spiking Neural Networks",
            "source": "crossref"
        },
        {
            "title": "Firing Rate of the Noisy Quadratic Integrate-and-Fire Neuron",
            "source": "crossref"
        },
        {
            "title": "SiamFC++: Towards Robust and Accurate Visual Tracking with Target Estimation Guidelines",
            "source": "crossref"
        },
        {
            "title": "Eye-blinking analysis as a marker of emotional states",
            "source": "crossref"
        },
        {
            "title": "SpikingJelly: An open-source machine learning infrastructure platform for spike-based intelligence",
            "source": "crossref"
        }
    ]
}
---

### Dataset Structure

In total, 4 individuals (3 male and 3 female) with different eye shapes participated. All of them were college students about 20 years old. A total of 91 eye movement video sequences were recorded.
