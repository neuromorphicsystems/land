---
{
    "name": "Amini2022",
    "aliases": [],
    "year": 2022,
    "modality": [
        "Vision"
    ],
    "sensors": [
        "Prophesee Gen3"
    ],
    "other_sensors": [
        "BFS-PGE-23S3C-CS RGB Camera",
        "Velo-dyne VLS-128 LiDAR"
    ],
    "category": "Robotic and Moving Vehicle Datasets",
    "subcategory": [
        "Autonomous Driving"
    ],
    "task": "Autonomous Driving",
    "dataset_properties": {
        "available_online": false,
        "has_real_data": false,
        "has_simulated_data": true,
        "has_ground_truth": true,
        "has_frames": true,
        "has_biases": false,
        "distribution_methods": [
            "Dropbox"
        ],
        "file_formats": [
            "CSV"
        ],
        "availability_comment": "Only a sample dataset is available via the Github repository",
        "dataset_links": [
            {
                "name": "Dropbox",
                "url": "https://www.dropbox.com/s/62pao4mipyzk3xu/vista_traces.zip",
                "format": "CSV",
                "available": false
            }
        ]
    },
    "paper": {
        "title": "VISTA 2.0: An Open, Data-driven Simulator for Multimodal Sensing and Policy Learning for Autonomous Vehicles",
        "doi": "10.1109/ICRA46639.2022.9812276",
        "authors": [
            "Alexander Amini",
            "Tsun-Hsuan Wang",
            "Igor Gilitschenski",
            "Wilko Schwarting",
            "Zhijian Liu",
            "Song Han",
            "Sertac Karaman",
            "Daniela Rus"
        ],
        "abstract": "Simulation has the potential to transform the development of robust algorithms for mobile agents deployed in safety-critical scenarios. However, the poor photorealism and lack of diverse sensor modalities of existing simulation engines remain key hurdles towards realizing this potential. Here, we present VISTA \u2020 \u2020 Full code release for the VISTA data-driven simulation engine is available here: vista.csail.mit.edu., an open source, data-driven simulator that integrates multiple types of sensors for autonomous vehicles. Using high fidelity, real-world datasets, VISTA represents and simulates RGB cameras, 3D LiDAR, and event-based cameras, enabling the rapid generation of novel viewpoints in simulation and thereby enriching the data available for policy learning with corner cases that are difficult to capture in the physical world. Using VISTA, we demonstrate the ability to train and test perception-to-control policies across each of the sensor types and showcase the power of this approach via deployment on a full scale autonomous vehicle. The policies learned in VISTA exhibit sim-to-real transfer without modification and greater robustness than those trained exclusively on real-world data.",
        "open_access": false
    },
    "citation_counts": [
        {
            "source": "crossref",
            "count": 46,
            "updated": "2025-07-02T08:38:57.720195"
        },
        {
            "source": "scholar",
            "count": 112,
            "updated": "2025-07-02T08:38:57.294527"
        }
    ],
    "links": [
        {
            "type": "preprint",
            "url": "https://arxiv.org/abs/2111.12083"
        },
        {
            "type": "paper",
            "url": "https://ieeexplore.ieee.org/document/9812276"
        },
        {
            "type": "github_page",
            "url": "https://github.com/vista-simulator/vista/"
        }
    ],
    "full_name": "",
    "additional_metadata": {
        "stereo": false
    },
    "bibtex": {
        "pages": "2419--2426",
        "year": 2022,
        "month": "may",
        "author": "Amini, Alexander and Wang, Tsun-Hsuan and Gilitschenski, Igor and Schwarting, Wilko and Liu, Zhijian and Han, Song and Karaman, Sertac and Rus, Daniela",
        "publisher": "IEEE",
        "booktitle": "2022 {International} {Conference} on {Robotics} and {Automation} ({ICRA})",
        "urldate": "2024-12-14",
        "language": "en",
        "doi": "10.1109/ICRA46639.2022.9812276",
        "url": "https://ieeexplore.ieee.org/document/9812276/",
        "shorttitle": "{VISTA} 2.0",
        "isbn": "978-1-72819-681-7",
        "copyright": "https://doi.org/10.15223/policy-029",
        "title": "{VISTA} 2.0: {An} {Open}, {Data}-driven {Simulator} for {Multimodal} {Sensing} and {Policy} {Learning} for {Autonomous} {Vehicles}",
        "address": "Philadelphia, PA, USA",
        "type": "inproceedings",
        "key": "amini_vista_2022"
    },
    "referenced_papers": [
        {
            "doi": "10.1109/ICRA.2018.8460487",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR42600.2020.01118",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICCV.2019.00943",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICRA40945.2020.9197408",
            "source": "crossref"
        },
        {
            "doi": "10.1038/s42256-020-00237-3",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2017.376",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2018.00945",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR42600.2020.00323",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR46437.2021.00345",
            "source": "crossref"
        },
        {
            "doi": "10.1109/IROS.2012.6386109",
            "source": "crossref"
        },
        {
            "doi": "10.1007/s11263-018-1073-7",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2018.00214",
            "source": "crossref"
        },
        {
            "doi": "10.1109/LRA.2021.3064284",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICCV.2019.00290",
            "source": "crossref"
        },
        {
            "doi": "10.1109/LRA.2021.3068885",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR46437.2021.01589",
            "source": "crossref"
        },
        {
            "doi": "10.1109/3DV50981.2020.00063",
            "source": "crossref"
        },
        {
            "doi": "10.1109/LRA.2021.3060707",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2019.00398",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR42600.2020.00364",
            "source": "crossref"
        },
        {
            "doi": "10.1109/LRA.2020.2966414",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICRA.2019.8793579",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TPAMI.2017.2769655",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2018.00568",
            "source": "crossref"
        },
        {
            "doi": "10.1177/0278364917691115",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2018.00938",
            "source": "crossref"
        },
        {
            "doi": "10.1109/IROS.2018.8594386",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICRA.2018.8461253",
            "source": "crossref"
        },
        {
            "title": "V2VNet: Vehicle-to-Vehicle Communication for Joint Perception and Prediction",
            "source": "crossref"
        },
        {
            "title": "AirSim: High-fidelity visual and physical simulation for autonomous vehicles",
            "source": "crossref"
        },
        {
            "title": "CARLA: An Open Urban Driving Simulator",
            "source": "crossref"
        },
        {
            "title": "Searching Efficient 3D Architectures with Sparse Point-Voxel Convolution",
            "source": "crossref"
        },
        {
            "title": "Unsupervised monoc-ular depth estimation with left-right consistency",
            "source": "crossref"
        },
        {
            "title": "Esim: an open event camera simulator",
            "source": "crossref"
        },
        {
            "title": "Guided policy search",
            "source": "crossref"
        },
        {
            "title": "U-net: Convolutional networks for biomedical image segmentation",
            "source": "crossref"
        },
        {
            "title": "On offline evaluation of vision-based driving models",
            "source": "crossref"
        },
        {
            "title": "Learning by cheating",
            "source": "crossref"
        }
    ]
}
---

### Dataset Structure
