---
{
    "name": "RA-L2021",
    "aliases": [],
    "year": 2021,
    "modality": [
        "Vision"
    ],
    "sensors": [
        "ESIM",
        "DAVIS240"
    ],
    "other_sensors": [
        "Vicon"
    ],
    "category": "Intensity Reconstruction, Optical Flow, and Frame Fusion",
    "subcategory": [
        "Camera Pose Estimation"
    ],
    "task": "Contrast Maximisation (Event Warping / Stabilisation)",
    "dataset_properties": {
        "available_online": true,
        "has_real_data": true,
        "has_simulated_data": true,
        "has_ground_truth": true,
        "has_frames": true,
        "has_biases": false,
        "distribution_methods": [
            "Direct Download"
        ],
        "file_formats": [
            "CSV"
        ],
        "availability_comment": "",
        "dataset_links": [
            {
                "name": "Direct Download",
                "url": "https://haram-kim.github.io/Globally_Aligned_Events/",
                "format": "CSV",
                "available": true
            }
        ],
        "size_gb": 0.3,
        "size_type": "Compressed"
    },
    "paper": {
        "title": "Real-Time Rotational Motion Estimation With Contrast Maximization Over Globally Aligned Events",
        "doi": "10.1109/LRA.2021.3088793",
        "authors": [
            "Haram Kim",
            "H. Jin Kim"
        ],
        "abstract": "Contrast maximization is an event camera application that can estimate angular velocity, depth, and optical-\ufb02ow using a subset of events observed in a temporal window. In the estimation of rotational motion, we can compute the angular position by integrating the angular velocity. However, the accumulation of drift error degrades the accuracy of motion estimation. If the contrast maximization framework utilizes events measured before the temporal window, the performance of the framework will be improved, including the alleviation of drift error in motion estimation. In this work, we utilize the globally aligned event data and propose the rotational position and velocity estimation method using an event camera only. The proposed algorithm not only maximizes contrast of an image of events in a single temporal window but also maximizes the contrast image of events observed over time. Our algorithm works in real-time by reducing additional computations of the existing contrast maximization. We con\ufb01rm the real-time operation with a single-core CPU on a laptop and show that the maximum error is within 3 degrees on public data sets and acquired real-world data sets. To contribute to the community, we provide the source code and the real-world data sets to the public.",
        "open_access": false
    },
    "citation_counts": [
        {
            "source": "crossref",
            "count": 29,
            "updated": "2025-07-01T08:05:56.414650"
        },
        {
            "source": "scholar",
            "count": 39,
            "updated": "2025-07-01T08:05:56.061692"
        }
    ],
    "links": [
        {
            "type": "paper",
            "url": "https://ieeexplore.ieee.org/document/9454404/"
        },
        {
            "type": "project_page",
            "url": "https://haram-kim.github.io/Globally_Aligned_Events/"
        }
    ],
    "full_name": "",
    "additional_metadata": {
        "stereo": false
    },
    "bibtex": {
        "pages": "6016--6023",
        "year": 2021,
        "month": "jul",
        "author": "Kim, Haram and Kim, H. Jin",
        "journal": "IEEE Robotics and Automation Letters",
        "urldate": "2024-04-13",
        "number": "3",
        "language": "en",
        "doi": "10.1109/LRA.2021.3088793",
        "url": "https://ieeexplore.ieee.org/document/9454404/",
        "issn": "2377-3766, 2377-3774",
        "copyright": "https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html",
        "volume": "6",
        "title": "Real-{Time} {Rotational} {Motion} {Estimation} {With} {Contrast} {Maximization} {Over} {Globally} {Aligned} {Events}",
        "type": "article",
        "key": "kim_real-time_2021"
    },
    "referenced_papers": [
        {
            "doi": "10.1109/ICCPHOT.2017.7951488",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2005.374",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2007.914337",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2019.01258",
            "source": "crossref"
        },
        {
            "doi": "10.1177/0278364917691115",
            "source": "crossref"
        },
        {
            "doi": "10.1109/IROS.2012.6385773",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2019.01032",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TPAMI.2019.2963386",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TPAMI.2017.2769655",
            "source": "crossref"
        },
        {
            "doi": "10.1007/978-3-319-46466-4_21",
            "source": "crossref"
        },
        {
            "doi": "10.1007/s11263-017-1050-6",
            "source": "crossref"
        },
        {
            "doi": "10.1109/LRA.2016.2645143",
            "source": "crossref"
        },
        {
            "doi": "10.1109/LRA.2016.2647639",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2018.00407",
            "source": "crossref"
        },
        {
            "doi": "10.5244/C.28.26",
            "source": "crossref"
        },
        {
            "title": "Globally optimal contrast maximisation for event-based motion estimation",
            "source": "crossref"
        },
        {
            "title": "Lecture 6.5-rmsprop, coursera: Neural networks for machine learning",
            "source": "crossref"
        },
        {
            "title": "ESIM: An open event camera simulator",
            "source": "crossref"
        }
    ]
}
---


### Dataset Structure