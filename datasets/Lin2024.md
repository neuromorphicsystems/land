---
{
    "name": "Lin2024",
    "aliases": [],
    "year": 2024,
    "modality": [
        "Vision"
    ],
    "sensors": [
        "DAVIS346"
    ],
    "other_sensors": [],
    "category": "Robotic and Moving Vehicle Datasets",
    "subcategory": [
        "Autonomous Driving",
        "3D Reconstruction"
    ],
    "task": "Neuromorphic Exposure Control",
    "dataset_properties": {
        "available_online": true,
        "has_real_data": true,
        "has_simulated_data": false,
        "has_ground_truth": false,
        "has_frames": true,
        "has_biases": false,
        "distribution_methods": [
            "Direct Download"
        ],
        "file_formats": [
            "aedat"
        ],
        "availability_comment": "",
        "dataset_links": [
            {
                "name": "Direct Download",
                "url": "https://datahub.hku.hk/articles/dataset/Embodied_Neuromorphic_Synergy_for_Lighting-robust_Machine_Vision_data_/26211053/1",
                "format": "aedat",
                "available": true
            }
        ],
        "size_gb": 71.51,
        "size_type": "Compressed"
    },
    "paper": {
        "title": "Embodied neuromorphic synergy for lighting-robust machine vision to see in extreme bright",
        "doi": "10.1038/s41467-024-54789-8",
        "authors": [
            "Shijie Lin",
            "Guangze Zheng",
            "Ziwei Wang",
            "Ruihua Han",
            "Wanli Xing",
            "Zeqing Zhang",
            "Yifan Peng",
            "Jia Pan"
        ],
        "abstract": "Proper exposure settings are crucial for modern machine vision cameras to accurately convert light into clear images. However, traditional auto-exposure solutions are vulnerable to illumination changes, splitting the continuous acquisition of unsaturated images, which significantly degrades the overall performance of underlying intelligent systems. Here we present the neuromorphic exposure control (NEC) system. This system effectively alleviates the longstanding saturation problem at its core by exploiting bio-principles found in peripheral vision to compute a trilinear event double integral (TEDI). This approach enables accurate connections between events and frames in the physics space for swift irradiance prediction, ultimately facilitating rapid control parameter updates. Our experimental results demonstrate the remarkable efficiency, low latency, superior generalization capability, and bio-inspired nature of the NEC in delivering timely and robust neuromorphic synergy for lighting-robust machine vision across a wide range of real-world applications. These applications encompass autonomous driving, mixed-reality, and three-dimensional reconstruction.",
        "open_access": false
    },
    "citation_counts": [
        {
            "source": "crossref",
            "count": 0,
            "updated": "2025-06-12T13:46:19.010499"
        },
        {
            "source": "scholar",
            "count": 3,
            "updated": "2025-06-12T13:46:18.829134"
        }
    ],
    "links": [
        {
            "type": "paper",
            "url": "https://www.nature.com/articles/s41467-024-54789-8"
        },
        {
            "type": "github_page",
            "url": "https://github.com/eleboss/NEC"
        }
    ],
    "full_name": "",
    "additional_metadata": {
        "stereo": false
    },
    "bibtex": {
        "pages": "10781",
        "year": 2024,
        "month": "dec",
        "author": "Lin, Shijie and Zheng, Guangze and Wang, Ziwei and Han, Ruihua and Xing, Wanli and Zhang, Zeqing and Peng, Yifan and Pan, Jia",
        "journal": "Nature Communications",
        "urldate": "2025-01-04",
        "number": "1",
        "language": "en",
        "doi": "10.1038/s41467-024-54789-8",
        "url": "https://www.nature.com/articles/s41467-024-54789-8",
        "issn": "2041-1723",
        "volume": "15",
        "title": "Embodied neuromorphic synergy for lighting-robust machine vision to see in extreme bright",
        "type": "article",
        "key": "lin_embodied_2024"
    },
    "referenced_papers": [
        {
            "doi": "10.1038/s41559-020-01358-z",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICRA48506.2021.9561028",
            "source": "crossref"
        },
        {
            "doi": "10.1038/d41586-024-00387-z",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TRO.2015.2463671",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICRA.2017.7989449",
            "source": "crossref"
        },
        {
            "doi": "10.1117/12.342854",
            "source": "crossref"
        },
        {
            "doi": "10.1109/30.663747",
            "source": "crossref"
        },
        {
            "doi": "10.1007/978-3-319-02895-8_4",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ROBOT.2010.5509978",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TCSVT.2018.2846292",
            "source": "crossref"
        },
        {
            "doi": "10.1109/LRA.2021.3058909",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICVS.2006.26",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR46437.2021.00762",
            "source": "crossref"
        },
        {
            "doi": "10.3390/s22030835",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICCV51070.2023.01129",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2014.2342715",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2007.914337",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TPAMI.2004.88",
            "source": "crossref"
        },
        {
            "doi": "10.1038/s41467-021-24880-5",
            "source": "crossref"
        },
        {
            "doi": "10.1038/s41467-022-28487-2",
            "source": "crossref"
        },
        {
            "doi": "10.1126/scirobotics.abl8419",
            "source": "crossref"
        },
        {
            "doi": "10.48550/arXiv.1906.07155",
            "source": "crossref"
        },
        {
            "doi": "10.48550/arXiv.2303.07399",
            "source": "crossref"
        },
        {
            "doi": "10.1023/B:VISI.0000029664.99615.94",
            "source": "crossref"
        },
        {
            "doi": "10.1038/s41467-020-18353-4",
            "source": "crossref"
        },
        {
            "doi": "10.1038/s41467-024-44694-5",
            "source": "crossref"
        },
        {
            "doi": "10.1038/s41467-021-25637-w",
            "source": "crossref"
        },
        {
            "doi": "10.1038/s41467-023-44554-8",
            "source": "crossref"
        },
        {
            "doi": "10.1038/s41586-021-03259-y",
            "source": "crossref"
        },
        {
            "doi": "10.48550/arXiv.2305.05925",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2019.00698",
            "source": "crossref"
        },
        {
            "doi": "10.1088/1361-6420/ace7c7",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TED.2017.2717848",
            "source": "crossref"
        }
    ]
}
---


### Dataset Structure