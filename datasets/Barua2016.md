---
{
    "name": "Barua2016",
    "aliases": [],
    "year": 2016,
    "modality": [
        "Vision"
    ],
    "sensors": [
        "DVS128"
    ],
    "other_sensors": [],
    "category": "Human-centric Recordings",
    "subcategory": [
        "Face Detection"
    ],
    "task": "Face Detection",
    "dataset_properties": {
        "available_online": false,
        "has_real_data": true,
        "has_simulated_data": false,
        "has_ground_truth": false,
        "has_frames": false,
        "has_biases": false,
        "distribution_methods": [
            "None"
        ],
        "file_formats": [],
        "availability_comment": "",
        "dataset_links": []
    },
    "paper": {
        "title": "Direct Face Detection and Video Reconstruction from Event Cameras",
        "doi": "10.1109/WACV.2016.7477561",
        "authors": [
            "Souptik Barua",
            "Yoshitaka Miyatani",
            "Ashok Veeraraghavan"
        ],
        "abstract": "Event cameras are emerging as a new class of cameras, to potentially rival conventional CMOS cameras, because of their high speed operation and low power consumption. Pixels in an event camera operate in parallel and fire asynchronous spikes when individual pixels encounter a change in intensity that is greater than a pre-determined threshold. Such event-based cameras have an immense potential in battery-operated or always-on application scenarios, owing to their low power consumption. These event-based cameras can be used for direct detection from event streams, and we demonstrate this potential using face detection as an example application. We first propose and develop a patch-based model for the event streams acquired from such cameras. We demonstrate the utility and robustness of the patch-based model for event-based video reconstruction and event-based direct face detection. We are able to reconstruct images and videos at over 2,000 fps from the acquired event streams. In addition, we demonstrate the first direct face detection from event streams, highlighting the potential of these event-based cameras for power-efficient vision applications.",
        "open_access": false
    },
    "citation_counts": [
        {
            "source": "crossref",
            "count": 90,
            "updated": "2025-06-11T17:41:44.146617"
        },
        {
            "source": "scholar",
            "count": 157,
            "updated": "2025-06-11T17:41:43.998127"
        }
    ],
    "links": [
        {
            "type": "paper",
            "url": "https://ieeexplore.ieee.org/abstract/document/7477561"
        }
    ],
    "full_name": "",
    "additional_metadata": {
        "num_subjects": "30",
        "stereo": false
    },
    "bibtex": {
        "pages": "1--9",
        "year": 2016,
        "month": "mar",
        "author": "Barua, Souptik and Miyatani, Yoshitaka and Veeraraghavan, Ashok",
        "publisher": "IEEE",
        "booktitle": "2016 {IEEE} {Winter} {Conference} on {Applications} of {Computer} {Vision} ({WACV})",
        "urldate": "2024-08-16",
        "language": "en",
        "doi": "10.1109/WACV.2016.7477561",
        "url": "http://ieeexplore.ieee.org/document/7477561/",
        "isbn": "978-1-5090-0641-0",
        "title": "Direct face detection and video reconstruction from event cameras",
        "address": "Lake Placid, NY, USA",
        "type": "inproceedings",
        "key": "barua_direct_2016"
    },
    "referenced_papers": [
        {
            "doi": "10.1109/CVPR.2001.990517",
            "source": "crossref"
        },
        {
            "doi": "10.1109/IROS.2014.6942940",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TIP.2010.2050625",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICCV.2005.74",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICPR.2004.1333733",
            "source": "crossref"
        },
        {
            "doi": "10.1023/B:VISI.0000013087.49260.fb",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2012.6247976",
            "source": "crossref"
        },
        {
            "doi": "10.1007/BF02678430",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ISCAS.2007.378038",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TIP.2006.881969",
            "source": "crossref"
        },
        {
            "doi": "10.1109/AFGR.2004.1301514",
            "source": "crossref"
        },
        {
            "doi": "10.1016/S0031-3203(03)00062-1",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ECMR.2013.6698817",
            "source": "crossref"
        },
        {
            "doi": "10.1109/34.935848",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICCPHOT.2015.7168370",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TSP.2006.881199",
            "source": "crossref"
        },
        {
            "doi": "10.1007/11744023_45",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TNNLS.2013.2273537",
            "source": "crossref"
        },
        {
            "doi": "10.1007/978-3-540-24670-1_6",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICIP.2004.1418823",
            "source": "crossref"
        },
        {
            "doi": "10.3389/fnins.2013.00275",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICCV.2005.31",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ISCAS.2009.5117867",
            "source": "crossref"
        },
        {
            "doi": "10.5244/C.28.26",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2015.7299170",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2004.1315144",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2007.914337",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICCV.2001.937655",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TIP.2007.911828",
            "source": "crossref"
        },
        {
            "title": "Face detection, pose estimation, and landmark localization in the wild",
            "source": "crossref"
        },
        {
            "title": "Efficient implementation of the k-svd algorithm using batch orthogonal matching pursuit",
            "source": "crossref"
        },
        {
            "title": "Orthogonal matching pursuit: Recursive function approximation with applications to wavelet decomposition",
            "source": "crossref"
        },
        {
            "title": "Histograms of oriented gradients for human detection",
            "source": "crossref"
        },
        {
            "title": "Fddb: A benchmark for face detection in unconstrained settings",
            "source": "crossref"
        },
        {
            "title": "K-svd: An algorithm for designing overcomplete dictionaries for sparse representation",
            "source": "crossref"
        },
        {
            "title": "Asynchronous event-based 3d reconstruction from neuromorphic retinas",
            "source": "crossref"
        },
        {
            "title": "Kullback-leibler boosting",
            "source": "crossref"
        }
    ]
}
---

### Dataset Structure

Dataset contains 15,716 face event patches of size 40 Ã— 40 pixels from 30 people

The network was trained using synthetic events, but tested on real event-based data from a DVS128.
