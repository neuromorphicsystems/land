---
{
    "name": "Event-Based Automotive Collision Detection Dataset",
    "aliases": [],
    "year": 2025,
    "modalities": [
        "Vision"
    ],
    "sensors": [
        "CARLA"
    ],
    "other_sensors": [],
    "category": "Robotic and Moving Vehicle Datasets",
    "tags": [
        "Vehicle Detection",
        "Collision Detection"
    ],
    "description": "Event-Based Automotive Collision Detection Dataset",
    "dataset_properties": {
        "available_online": true,
        "has_real_data": false,
        "has_simulated_data": true,
        "has_ground_truth": true,
        "has_frames": true,
        "has_biases": false,
        "distribution_methods": [
            "Figshare"
        ],
        "file_formats": [
            "Numpy"
        ],
        "availability_comment": "",
        "dataset_links": [
            {
                "name": "Figshare",
                "url": "https://sussex.figshare.com/articles/dataset/Carla_Simulator_collision_scenario_DVS_Sequences_from_Bio-inspired_event-based_looming_object_detection_for_automotive_collision_avoidance/29114609/1?file=54931133",
                "format": "Numpy",
                "available": true
            }
        ],
        "size_gb": 14.06,
        "size_type": "Compressed"
    },
    "paper": {
        "title": "Bio-inspired event-based looming object detection for automotive collision avoidance",
        "doi": "10.1088/2634-4386/add0da",
        "authors": [
            "F Schubert",
            "J C Knight",
            "A Philippides",
            "T Nowotny"
        ],
        "abstract": "Low-latency sensory processing is a key requirement of collision avoidance systems for automated driving. Event-based cameras have been proposed and investigated as a new type of sensor for faster and more efficient collision detection. In this study, we investigate an insect vision-inspired network that detects looming objects in traffic situations using event-based camera data. As such, it represents a lightweight alternative to large neural networks applied in vision-based driving assistance systems. Using simulated driving accident scenarios, we find that our system can reliably detect colliding vehicles up to 1.3 s before the collision. Furthermore, we demonstrate the effectiveness of nonlinear radial motion opponency filtering in addressing the challenges of optical flow-based looming detection.",
        "open_access": true
    },
    "citation_counts": [
        {
            "source": "crossref",
            "count": 0,
            "updated": "2025-09-18T23:17:05.091512"
        }
    ],
    "links": [
        {
            "type": "github_page",
            "url": "https://github.com/FabianSchubert/Bio-Inspired-Event-Based-Looming-Object-Detection-for-Automotive-Collision-Avoidance"
        },
        {
            "type": "paper",
            "url": "https://iopscience.iop.org/article/10.1088/2634-4386/add0da/meta"
        }
    ],
    "full_name": "",
    "additional_metadata": {
        "num_recordings": "1406"
    },
    "referenced_papers": [
        {
            "doi": "10.1038/nature24626",
            "source": "crossref"
        },
        {
            "doi": "10.1016/j.cois.2024.101180",
            "source": "crossref"
        },
        {
            "doi": "10.1016/j.cub.2012.01.007",
            "source": "crossref"
        },
        {
            "doi": "10.1007/BF00698057",
            "source": "crossref"
        },
        {
            "doi": "10.1016/S0921-8890(99)00063-9",
            "source": "crossref"
        },
        {
            "doi": "10.1016/j.isci.2023.106337",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2014.2342715",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2007.914337",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TPAMI.2020.3008413",
            "source": "crossref"
        },
        {
            "doi": "10.1371/journal.pcbi.1000701",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TNN.2006.873286",
            "source": "crossref"
        },
        {
            "doi": "10.1016/S0042-6989(99)00002-4",
            "source": "crossref"
        },
        {
            "doi": "10.1146/annurev-neuro-072116-031335",
            "source": "crossref"
        },
        {
            "doi": "10.1007/s00359-022-01610-w",
            "source": "crossref"
        },
        {
            "doi": "10.1515/znb-1956-9-1004",
            "source": "crossref"
        },
        {
            "doi": "10.1016/j.cub.2008.11.001",
            "source": "crossref"
        },
        {
            "doi": "10.1007/BF00272517",
            "source": "crossref"
        },
        {
            "doi": "10.1016/j.neuron.2017.03.010",
            "source": "crossref"
        },
        {
            "doi": "10.1016/j.cub.2019.01.079",
            "source": "crossref"
        },
        {
            "doi": "10.1242/bio.012690",
            "source": "crossref"
        },
        {
            "doi": "10.1109/70.660840",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TRO.2005.858857",
            "source": "crossref"
        },
        {
            "doi": "10.1007/s10514-009-9140-0",
            "source": "crossref"
        },
        {
            "doi": "10.7554/eLife.72067",
            "source": "crossref"
        },
        {
            "doi": "10.1016/0734-189X(89)90035-2",
            "source": "crossref"
        },
        {
            "doi": "10.1109/70.338534",
            "source": "crossref"
        },
        {
            "doi": "10.1007/s00138-004-0152-7",
            "source": "crossref"
        },
        {
            "doi": "10.1109/34.42840",
            "source": "crossref"
        },
        {
            "doi": "10.1109/LRA.2021.3068942",
            "source": "crossref"
        },
        {
            "doi": "10.1038/4580",
            "source": "crossref"
        },
        {
            "doi": "10.1002/wcs.142",
            "source": "crossref"
        },
        {
            "doi": "10.25377/sussex.29114609.v1",
            "source": "crossref"
        },
        {
            "doi": "10.1068/p050437",
            "source": "crossref"
        },
        {
            "doi": "10.3389/fninf.2021.659005",
            "source": "crossref"
        },
        {
            "doi": "10.1609/aaai.v33i01.3301978",
            "source": "crossref"
        },
        {
            "doi": "10.3846/16484142.2007.9638118",
            "source": "crossref"
        },
        {
            "doi": "10.1080/00423110701538320",
            "source": "crossref"
        },
        {
            "doi": "10.1145/3394171.3413827",
            "source": "crossref"
        },
        {
            "doi": "10.1126/scirobotics.aaz9712",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TRO.2024.3454410",
            "source": "crossref"
        },
        {
            "doi": "10.3389/fnins.2014.00009",
            "source": "crossref"
        },
        {
            "doi": "10.1109/IROS51168.2021.9636327",
            "source": "crossref"
        },
        {
            "doi": "10.1080/15389588.2022.2131403",
            "source": "crossref"
        },
        {
            "doi": "10.1016/j.aap.2022.106686",
            "source": "crossref"
        },
        {
            "doi": "10.3389/fnbot.2017.00028",
            "source": "crossref"
        },
        {
            "doi": "10.1109/LRA.2021.3100153",
            "source": "crossref"
        },
        {
            "doi": "10.1007/s40815-022-01330-y",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR46437.2021.00700",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TIV.2023.3307157",
            "source": "crossref"
        },
        {
            "title": "Ultra-selective looming detection from radial motion opponency",
            "source": "crossref"
        },
        {
            "title": "Recent advances in insect vision in a 3D world: looming stimuli and escape behaviour",
            "source": "crossref"
        },
        {
            "title": "Loom-sensitive neurons link computation to action in the Drosophila visual system",
            "source": "crossref"
        },
        {
            "title": "The anatomy and output connection of a locust visual interneurone; the lobular giant movement detector (LGMD) neurone",
            "source": "crossref"
        },
        {
            "title": "Collision avoidance using a model of the locust LGMD neuron",
            "source": "crossref"
        },
        {
            "title": "OppLoD: the opponency based looming detector, model extension of looming sensitivity from LGMD to LPLC2",
            "source": "crossref"
        },
        {
            "title": "A fly inspired solution to looming detection for collision avoidance",
            "source": "crossref"
        },
        {
            "title": "A 240 \u00d7 180 130 dB 3 \u00b5s latency global shutter spatiotemporal vision sensor",
            "source": "crossref"
        },
        {
            "title": "4.1 a 640\u2009\u00d7\u2009480 dynamic vision sensor with a 9 \u00b5m pixel and 300Meps address-event representation",
            "source": "crossref"
        },
        {
            "title": "A 128 \u00d7 128 120 dB 15 \u00b5s latency asynchronous temporal contrast vision sensor",
            "source": "crossref"
        },
        {
            "title": "Event-based vision: a survey",
            "source": "crossref"
        },
        {
            "title": "Non-linear neuronal responses as an emergent property of afferent networks: a case study of the locust lobula giant movement detector",
            "source": "crossref"
        },
        {
            "title": "Collision detection in complex dynamic scenes using an LGMD-based visual neural network with feature enhancement",
            "source": "crossref"
        },
        {
            "title": "Motion detection in insect orientation and navigation",
            "source": "crossref"
        },
        {
            "title": "Visual circuits for direction selectivity",
            "source": "crossref"
        },
        {
            "title": "Optic flow based spatial vision in insects",
            "source": "crossref"
        },
        {
            "title": "Systemtheoretische analyse der zeit-, reihenfolgen- und vorzeichenauswertung bei der bewegungsperzeption des r\u00fcsselk\u00e4fers chlorophanus",
            "source": "crossref"
        },
        {
            "title": "Drosophila\u2019s view on insect vision",
            "source": "crossref"
        },
        {
            "title": "Flight control in Drosophila by visual perception of motion",
            "source": "crossref"
        },
        {
            "title": "The emergence of directional selectivity in the visual motion pathway of Drosophila",
            "source": "crossref"
        },
        {
            "title": "Neural basis for looming size and velocity encoding in the Drosophila giant fiber escape pathway",
            "source": "crossref"
        },
        {
            "title": "Local motion detectors are required for the computation of expansion flow-fields",
            "source": "crossref"
        },
        {
            "title": "Real-time obstacle avoidance using central flow divergence and peripheral flow",
            "source": "crossref"
        },
        {
            "title": "Fly-inspired visual steering of an ultralight indoor aircraft",
            "source": "crossref"
        },
        {
            "title": "Implementation of wide-field integration of optic flow for autonomous quadrotor navigation",
            "source": "crossref"
        },
        {
            "title": "Shallow neural networks trained to detect collisions recover features of visual loom-selective neurons",
            "source": "crossref"
        },
        {
            "title": "A direct method for locating the focus of expansion",
            "source": "crossref"
        },
        {
            "title": "Time-to-collision from first-order models of the motion field",
            "source": "crossref"
        },
        {
            "title": "Finding the focus of expansion and estimating range using optical flow images and a matched filter",
            "source": "crossref"
        },
        {
            "title": "Obstacle avoidance using flow field divergence",
            "source": "crossref"
        },
        {
            "title": "Driving assistance system based on the detection of head-on collisions",
            "source": "crossref"
        },
        {
            "title": "DSEC: a stereo event camera dataset for driving scenarios",
            "source": "crossref"
        },
        {
            "title": "Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects",
            "source": "crossref"
        },
        {
            "title": "Predictive coding",
            "source": "crossref"
        },
        {
            "title": "CARLA: an open urban driving simulator",
            "source": "crossref"
        },
        {
            "title": "Collision detection: an improved deep learning approach using SENet and ResNext",
            "source": "crossref"
        },
        {
            "title": "Non-metric navigation for mobile robot using optical flow",
            "source": "crossref"
        },
        {
            "title": "Globally optimal event-based divergence estimation for ventral landing",
            "source": "crossref"
        },
        {
            "title": "Toward 30-gram autonomous indoor aircraft: vision-based obstacle avoidance and altitude control",
            "source": "crossref"
        },
        {
            "title": "Carla Simulator collision scenario DVS Sequences from Bio-inspired event-based looming object detection for automotive collision avoidance",
            "source": "crossref"
        },
        {
            "title": "A theory of visual control of braking based on information about time-to-collision",
            "source": "crossref"
        },
        {
            "title": "PyGeNN: a Python library for GPU-enhanced neural networks",
            "source": "crossref"
        },
        {
            "title": "Crash to not crash: learn to identify dangerous vehicles using a simulator",
            "source": "crossref"
        },
        {
            "title": "Analysis of emergency braking of a vehicle",
            "source": "crossref"
        },
        {
            "title": "Evaluation of emergency braking deceleration for accident reconstruction",
            "source": "crossref"
        },
        {
            "title": "Investigation of braking deceleration in vehicle",
            "source": "crossref"
        },
        {
            "title": "V2e: from video frames to realistic DVS events",
            "source": "crossref"
        },
        {
            "title": "A large scale event-based detection dataset for automotive",
            "source": "crossref"
        },
        {
            "title": "Uncertainty-based traffic accident anticipation with spatio-temporal relational learning",
            "source": "crossref"
        },
        {
            "title": "Time-to-collision as a cue for decision-making in braking",
            "source": "crossref"
        },
        {
            "title": "Dynamic obstacle avoidance for quadrotors with event cameras",
            "source": "crossref"
        },
        {
            "title": "EvTTC: an event camera dataset for time-to-collision estimation",
            "source": "crossref"
        },
        {
            "title": "Event-aided time-to-collision estimation for autonomous driving",
            "source": "crossref"
        },
        {
            "title": "Asynchronous blob tracker for event cameras",
            "source": "crossref"
        },
        {
            "title": "Asynchronous visual event-based time-to-contact",
            "source": "crossref"
        },
        {
            "title": "Time-to-contact map by joint estimation of up-to-scale inverse depth and global motion using a single event camera",
            "source": "crossref"
        },
        {
            "title": "A unifying contrast maximization framework for event cameras, with applications to motion, depth and optical flow estimation",
            "source": "crossref"
        },
        {
            "title": "EVReflex: dense time-to-impact prediction for event-based obstacle avoidance",
            "source": "crossref"
        },
        {
            "title": "Effects on crash risk of automatic emergency braking systems for pedestrians and bicyclists",
            "source": "crossref"
        },
        {
            "title": "Effects of automatic emergency braking systems on pedestrian crash risk",
            "source": "crossref"
        },
        {
            "title": "Bioinspired event-driven collision avoidance algorithm based on optic flow",
            "source": "crossref"
        },
        {
            "title": "Obstacle avoidance and target acquisition for robot navigation using a mixed signal analog/digital neuromorphic processing system",
            "source": "crossref"
        },
        {
            "title": "FAITH: fast iterative half-plane focus of expansion estimation using event-based optic flow",
            "source": "crossref"
        },
        {
            "title": "Event-based adaptive fuzzy asymptotic tracking control of quadrotor unmanned aerial vehicle with obstacle avoidance",
            "source": "crossref"
        },
        {
            "title": "Multi-modal fusion transformer for end-to-end autonomous driving",
            "source": "crossref"
        },
        {
            "title": "Multi-modal sensor fusion for auto driving perception: a survey",
            "source": "crossref"
        },
        {
            "title": "Radar-camera fusion for object detection and semantic segmentation in autonomous driving: a comprehensive review",
            "source": "crossref"
        },
        {
            "title": "Event-Based Automotive Collision Detection",
            "source": "crossref"
        }
    ],
    "bibtex": {
        "pages": "024016",
        "month": "jun",
        "year": 2025,
        "author": "Schubert, F and Knight, J C and Philippides, A and Nowotny, T",
        "publisher": "IOP Publishing",
        "journal": "Neuromorphic Computing and Engineering",
        "number": "2",
        "doi": "10.1088/2634-4386/add0da",
        "url": "http://dx.doi.org/10.1088/2634-4386/add0da",
        "issn": "2634-4386",
        "volume": "5",
        "title": "Bio-inspired event-based looming object detection for automotive collision avoidance",
        "type": "article",
        "key": "Schubert_2025"
    }
}
---

# Dataset Description

This dataset comprises 1406 sequences (4 sec each) of simulated dynamic vision sensor data from virtual driving and collision scenarios with cars and pedestrians, created using the CARLA Simulator.

Data Formats

Each sequence is stored in a separate folder, which contains of an event.npy file and a sim_data.npz metadata file.
The event.npy file holds a structured numpy array, with each element corresponding to an event. The data fields of the structured array are

The data fields of the structured array are [("t", "< u4"), ("x", "< u2"), ("y", "< u2"), ("p", "< u2")]
- t: event time in milliseconds
- x, y: pixel coordinate of the event
- p: polarity, where 0 is a negative event, and 1 is positive.

Here, "< u4" and "< u2" refer to 32 bit and 16 bit unsigned integers, respectively.