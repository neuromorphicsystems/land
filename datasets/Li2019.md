---
{
    "name": "Li2019",
    "aliases": [],
    "year": 2019,
    "modality": [
        "Vision"
    ],
    "sensors": [
        "DVS128",
        "DAVIS240"
    ],
    "other_sensors": [],
    "category": "Object Detection, Classification, and Tracking",
    "subcategory": [
        "Object Tracking"
    ],
    "task": "Object Tracking",
    "dataset_properties": {
        "available_online": false,
        "has_real_data": true,
        "has_simulated_data": false,
        "has_ground_truth": false,
        "has_frames": false,
        "has_biases": false,
        "distribution_methods": [
            "Figshare"
        ],
        "file_formats": [
            "aedat"
        ],
        "availability_comment": "",
        "dataset_links": [
            {
                "name": "Figshare",
                "url": "https://figshare.com/s/70565903453eef7c3965",
                "format": "aedat",
                "available": false
            }
        ],
        "size_gb": 0.14,
        "size_type": "Compressed"
    },
    "paper": {
        "title": "Robust Event-Based Object Tracking Combining Correlation Filter and CNN Representation",
        "doi": "10.3389/fnbot.2019.00082",
        "authors": [
            "Hongmin Li",
            "Luping Shi"
        ],
        "abstract": "Object tracking based on the event-based camera or dynamic vision sensor (DVS) remains a challenging task due to the noise events, rapid change of event-stream shape, chaos of complex background textures, and occlusion. To address the challenges, this paper presents a robust event-stream object tracking method based on correlation filter mechanism and convolutional neural network (CNN) representation. In the proposed method, rate coding is used to encode the event-stream object. Feature representations from hierarchical convolutional layers of a pre-trained CNN are used to represent the appearance of the rate encoded event-stream object. Results prove that the proposed method not only achieves good tracking performance in many complicated scenes with noise events, complex background textures, occlusion, and intersected trajectories, but also is robust to variable scale, variable pose, and non-rigid deformations. In addition, the correlation filter-based method has the advantage of high speed. The proposed approach will promote the potential applications of these event-based vision sensors in autonomous driving, robots and many other high-speed scenes.",
        "open_access": true
    },
    "citation_counts": [
        {
            "source": "crossref",
            "count": 26,
            "updated": "2025-06-14T14:48:53.192311"
        },
        {
            "source": "scholar",
            "count": 41,
            "updated": "2025-06-14T14:48:52.566694"
        }
    ],
    "links": [
        {
            "type": "paper",
            "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2019.00082/full"
        }
    ],
    "full_name": "",
    "additional_metadata": {
        "num_recordings": "8",
        "stereo": false
    },
    "bibtex": {
        "pages": "82",
        "year": 2019,
        "month": "oct",
        "author": "Li, Hongmin and Shi, Luping",
        "journal": "Frontiers in Neurorobotics",
        "urldate": "2024-04-13",
        "language": "en",
        "doi": "10.3389/fnbot.2019.00082",
        "url": "https://www.frontiersin.org/article/10.3389/fnbot.2019.00082/full",
        "issn": "1662-5218",
        "volume": "13",
        "title": "Robust {Event}-{Based} {Object} {Tracking} {Combining} {Correlation} {Filter} and {CNN} {Representation}",
        "type": "article",
        "key": "li_robust_2019"
    },
    "referenced_papers": [
        {
            "doi": "10.1109/82.842110",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2010.5539960",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2014.2342715",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ISCAS.2009.5117867",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICCVW.2015.84",
            "source": "crossref"
        },
        {
            "doi": "10.1007/s00348-011-1207-y",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TPAMI.2014.2345390",
            "source": "crossref"
        },
        {
            "doi": "10.1007/978-3-642-33765-9_50",
            "source": "crossref"
        },
        {
            "doi": "10.3389/fnins.2016.00405",
            "source": "crossref"
        },
        {
            "doi": "10.5244/C.28.26",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TNNLS.2014.2352401",
            "source": "crossref"
        },
        {
            "doi": "10.1109/NVMTS.2015.7457498",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2007.914337",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICCV.2015.352",
            "source": "crossref"
        },
        {
            "doi": "10.1162/NECO_a_00720",
            "source": "crossref"
        },
        {
            "doi": "10.1111/j.1365-2818.2011.03565.x",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPRW.2012.6238892",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ISCAS.2010.5537289",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2012.2230553",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TRO.2012.2198930",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICRA.2017.7989517",
            "source": "crossref"
        },
        {
            "title": "Simultaneous optical flow and intensity estimation from an event camera",
            "source": "crossref"
        },
        {
            "title": "Point-to-point connectivity between neuromorphic chips using address events",
            "source": "crossref"
        },
        {
            "title": "Visual object tracking using adaptive correlation filters",
            "source": "crossref"
        },
        {
            "title": "A 240 \u00d7180 130 dB 3 \u03bcs latency global shutter spatiotemporal vision sensor",
            "source": "crossref"
        },
        {
            "title": "A pencil balancing robot using a pair of AER dynamic vision sensors",
            "source": "crossref"
        },
        {
            "title": "Convolutional features for correlation filter based visual tracking",
            "source": "crossref"
        },
        {
            "title": "Toward real-time particle tracking using an event-based dynamic vision sensor",
            "source": "crossref"
        },
        {
            "title": "High-speed tracking with kernelized correlation filters",
            "source": "crossref"
        },
        {
            "title": "Exploiting the circulant structure of tracking-by-detection with kernels",
            "source": "crossref"
        },
        {
            "title": "DVS benchmark datasets for object tracking, action recognition, and object recognition",
            "source": "crossref"
        },
        {
            "title": "Simultaneous mosaicing and tracking with an event camera",
            "source": "crossref"
        },
        {
            "title": "Asynchronous event-based multikernel algorithm for high-speed visual features tracking",
            "source": "crossref"
        },
        {
            "title": "Real-time tracking based on neuromrophic vision. in Non-Volatile Memory Technology Symposium (NVMTS)",
            "source": "crossref"
        },
        {
            "title": "A 128 128 120 dB 15us latency asynchronous temporal contrast vision sensor",
            "source": "crossref"
        },
        {
            "title": "Embedded vision system for real-time object tracking using an asynchronous transient vision sensor",
            "source": "crossref"
        },
        {
            "title": "Hierarchical convolutional features for visual tracking",
            "source": "crossref"
        },
        {
            "title": "Visual tracking using neuromorphic asynchronous event-based cameras",
            "source": "crossref"
        },
        {
            "title": "Asynchronous event-based high speed vision for microparticle tracking",
            "source": "crossref"
        },
        {
            "title": "Spatiotemporal multiple persons tracking using dynamic vision sensor",
            "source": "crossref"
        },
        {
            "title": "High-speed object tracking using an asynchronous temporal contrast sensor",
            "source": "crossref"
        },
        {
            "title": "Dynamic stereo vision system for real-time tracking",
            "source": "crossref"
        },
        {
            "title": "A 128x128 1.5% contrast sensitivity 0.9% FPN 3\u03bcs Latency4mWAsynchronous frame-free dynamic vision sensor using transimpedance preamplifier",
            "source": "crossref"
        },
        {
            "title": "Asynchronsou event-based visual shape tracking for stable haptic feedback in microrobotics",
            "source": "crossref"
        },
        {
            "title": "Event-based feature tracking with probabilistic data association",
            "source": "crossref"
        }
    ]
}
---


### Dataset Structure 

- Consists of 8 recordings, with 3 recorded using a DVS128 and the other five were captured with a DAVIS240C