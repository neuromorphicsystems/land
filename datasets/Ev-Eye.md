---
{
    "name": "Ev-Eye",
    "aliases": [],
    "year": 2024,
    "modalities": [
        "Vision"
    ],
    "sensors": [
        "DAVIS346"
    ],
    "other_sensors": [
        "Tobii Pro Glasses 3"
    ],
    "category": "Human-centric Recordings",
    "tags": [
        "Gaze Tracking",
        "Eye Tracking",
        "Blink Detection"
    ],
    "description": "Eye and Gaze Tracking",
    "dataset_properties": {
        "available_online": true,
        "has_real_data": true,
        "has_simulated_data": false,
        "has_ground_truth": false,
        "has_frames": true,
        "has_biases": false,
        "distribution_methods": [
            "OneDrive"
        ],
        "file_formats": [
            "Numpy"
        ],
        "availability_comment": "",
        "dataset_links": [
            {
                "name": "OneDrive",
                "url": "https://1drv.ms/f/s!Ar4TcaawWPssqmu-0vJ45vYR3OHw",
                "format": "Numpy",
                "available": true
            }
        ],
        "size_gb": 124.0,
        "size_type": "Compressed"
    },
    "paper": {
        "title": "Ev-eye: Rethinking high-frequency eye tracking through the lenses of event cameras",
        "doi": "10.5555/3666122.3668838",
        "authors": [
            "Guangrong Zhao",
            "Yurun Yang",
            "Jingwei Liu",
            "Ning Chen",
            "Yiran Shen",
            "Hongkai Wen"
        ],
        "abstract": "In this paper, we present EV-Eye, a first-of-its-kind large scale multimodal eye tracking dataset aimed at inspiring research on high-frequency eye/gaze tracking. EV-Eye utilizes an emerging bio-inspired event camera to capture independent pixel-level intensity changes induced by eye movements, achieving sub-microsecond latency. Our dataset was curated over a two-week period and collected from 48 participants encompassing diverse genders and age groups. It comprises over 1.5 million near-eye grayscale images and 2.7 billion event samples generated by two DAVIS346 event cameras. Additionally, the dataset contains 675 thousands scene images and 2.7 million gaze references captured by Tobii Pro Glasses 3 eye tracker for cross-modality validation. Compared with existing event-based high-frequency eye tracking datasets, our dataset is significantly larger in size, and the gaze references involve more natural eye movement patterns, i.e., fixation, saccade and smooth pursuit. Alongside the event data, we also present a hybrid eye tracking method as benchmark, which leverages both the near-eye grayscale images and event data for robust and high-frequency eye tracking. We show that our method achieves higher accuracy for both pupil and gaze estimation tasks compared to the existing solution.",
        "open_access": true
    },
    "citation_counts": [
        {
            "source": "Google Scholar",
            "count": 20,
            "updated": "2025-01-06 10:30:56.983664"
        }
    ],
    "links": [
        {
            "type": "preprint",
            "url": "https://papers.nips.cc/paper_files/paper/2023/hash/c41b5d8c1ba15b2aa83e4fa1541f02c8-Abstract-Datasets_and_Benchmarks.html"
        },
        {
            "type": "paper",
            "url": "https://dl.acm.org/doi/10.5555/3666122.3668838"
        },
        {
            "type": "github_page",
            "url": "https://github.com/Ningreka/EV-Eye"
        }
    ],
    "full_name": "",
    "additional_metadata": {
        "num_subjects": "48",
        "event_format": "(t, x, y, p)",
        "polarity_range": "(0, 1)",
        "time_resolution": "us",
        "stereo": true
    },
    "bibtex": {
        "note": "event-place: New Orleans, LA, USA",
        "year": 2024,
        "author": "Zhao, Guangrong and Yang, Yurun and Liu, Jingwei and Chen, Ning and Shen, Yiran and Wen, Hongkai and Lan, Guohao",
        "publisher": "Curran Associates Inc.",
        "booktitle": "Proceedings of the 37th {International} {Conference} on {Neural} {Information} {Processing} {Systems}",
        "doi": "10.5555/3666122.3668838",
        "title": "{EV}-{Eye}: rethinking high-frequency eye tracking through the lenses of event cameras",
        "series": "{NIPS} '23",
        "address": "Red Hook, NY, USA",
        "type": "inproceedings",
        "key": "zhao_ev-eye_2024"
    }
}
---

### Dataset Structure

The dataset contains recordings from 48 subjects. The dataset contains both frames and events from two synchronised DAVIS346 cameras. In addition, the dataset also contains scene images and reference data captured using a Tobii Pro Glasses 3 eye tracker. The dataset contains approximately 1.5m grayscale images alongside the event-based data. The total size of the dataset is approximately 124 Gb containing `.rar` files for each user).

The event data is provided in Numpy format, with each line corresponding to a single event. These events are stored as(t, x, y, p) vectors, with (0, 1) and `t` has a us. Alongside the event data, a separate directory contains the grayscale images recorded alongside the events from the DAVIS346 sensors. Note that there is a `frames` and `events` folder for the left and the right cameras for each user.
