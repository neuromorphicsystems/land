---
{
    "name": "Gaze-FELL",
    "aliases": [],
    "year": 2024,
    "modality": [
        "Vision"
    ],
    "sensors": [
        "DAVIS346"
    ],
    "other_sensors": [],
    "category": "Human-centric Recordings",
    "tags": [
        "Eye Tracking",
        "Blink Detection",
        "Gaze Tracking"
    ],
    "description": "Gaze vector tracking",
    "dataset_properties": {
        "available_online": false,
        "has_real_data": true,
        "has_simulated_data": false,
        "has_ground_truth": false,
        "has_frames": true,
        "has_biases": false,
        "distribution_methods": [],
        "file_formats": [],
        "availability_comment": "Dataset available on request",
        "dataset_links": []
    },
    "paper": {
        "title": "Gaze-Vector Estimation in the Dark with Temporally Encoded Event-driven Neural Networks",
        "doi": "10.48550/arXiv.2403.02909",
        "authors": [
            "Abeer Banerjee",
            "Naval K. Mehta",
            "Shyam S. Prasad",
            " Himanshu",
            "Sumeet Saurav",
            "Sanjay Singh"
        ],
        "abstract": "In this paper, we address the intricate challenge of gaze vector prediction, a pivotal task with applications ranging from human-computer interaction to driver monitoring systems. Our innovative approach is designed for the demanding setting of extremely low-light conditions, leveraging a novel temporal event encoding scheme, and a dedicated neural network architecture. The temporal encoding method seamlessly integrates Dynamic Vision Sensor (DVS) events with grayscale guide frames, generating consecutively encoded images for input into our neural network. This unique solution not only captures diverse gaze responses from participants within the active age group but also introduces a curated dataset tailored for low-light conditions. The encoded temporal frames paired with our network showcase impressive spatial localization and reliable gaze direction in their predictions. Achieving a remarkable 100-pixel accuracy of 100%, our research underscores the potency of our neural network to work with temporally consecutive encoded images for precise gaze vector predictions in challenging low-light videos, contributing to the advancement of gaze prediction technologies.",
        "open_access": false
    },
    "citation_counts": [
        {
            "source": "scholar",
            "count": 2,
            "updated": "2025-06-04T06:54:46.420112"
        }
    ],
    "links": [
        {
            "type": "preprint",
            "url": "https://arxiv.org/abs/2403.02909"
        },
        {
            "type": "paper",
            "url": "https://arxiv.org/abs/2403.02909"
        }
    ],
    "full_name": "Gaze Frames and Events in Low-Light (Gaze-FELL)",
    "additional_metadata": {
        "num_subjects": "5",
        "stereo": false
    },
    "bibtex": {
        "keywords": "Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing, Computer Science - Human-Computer Interaction",
        "note": "arXiv:2403.02909 [cs]",
        "year": 2024,
        "month": "mar",
        "author": "Banerjee, Abeer and Mehta, Naval K. and Prasad, Shyam S. and Himanshu and Saurav, Sumeet and Singh, Sanjay",
        "publisher": "arXiv",
        "urldate": "2025-01-06",
        "language": "en",
        "doi": "10.48550/arXiv.2403.02909",
        "url": "http://arxiv.org/abs/2403.02909",
        "title": "Gaze-{Vector} {Estimation} in the {Dark} with {Temporally} {Encoded} {Event}-driven {Neural} {Networks}",
        "type": "misc",
        "key": "Banerjee2024"
    }
}
---

### Dataset Structure

- Contains data from 5 subjects
-
