---
{
    "name": "Yang2024",
    "aliases": [],
    "year": 2024,
    "modality": [
        "Vision"
    ],
    "sensors": [
        "DAVIS346"
    ],
    "other_sensors": [],
    "category": "Filtering and De-noising",
    "subcategory": [
        "De-blurring",
        "High-Speed Video Reconstruction"
    ],
    "task": "Event-guided de-blurring",
    "dataset_properties": {
        "available_online": false,
        "has_real_data": true,
        "has_simulated_data": false,
        "has_ground_truth": false,
        "has_frames": true,
        "has_biases": false,
        "distribution_methods": [],
        "file_formats": [],
        "availability_comment": "",
        "dataset_links": []
    },
    "paper": {
        "title": "Latency Correction for Event-Guided Deblurring and Frame Interpolation",
        "doi": "10.1109/CVPR52733.2024.02359",
        "authors": [
            "Yixin Yang",
            "Jinxiu Liang",
            "Bohan Yu",
            "Yan Chen",
            "Jimmy S. Ren",
            "Boxin Shi"
        ],
        "abstract": "Event cameras, with their high temporal resolution, dynamic range, and low power consumption, are particularly good at time-sensitive applications like deblurring and frame interpolation. However, their performance is hindered by latency variability, especially under low-light conditions and with fast-moving objects. This paper addresses the challenge of latency in event cameras \u2014 the temporal discrepancy between the actual occurrence of changes in the corresponding timestamp assigned by the sensor. Focusing on event-guided deblurring and frame interpolation tasks, we propose a latency correction method based on a parameterized latency model. To enable data-driven learning, we develop an event-based temporal fidelity to describe the sharpness of latent images reconstructed from events and the corresponding blurry images, and reformulate the event-based double integral model differentiable to latency. The proposed method is validated using synthetic and realworld datasets, demonstrating the benefits of latency correction for deblurring and interpolation across different lighting conditions.",
        "open_access": false
    },
    "citation_counts": [
        {
            "source": "crossref",
            "count": 5,
            "updated": "2025-07-11T08:39:53.855544"
        },
        {
            "source": "scholar",
            "count": 11,
            "updated": "2025-07-11T08:39:53.512636"
        }
    ],
    "links": [
        {
            "type": "preprint",
            "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Yang_Latency_Correction_for_Event-guided_Deblurring_and_Frame_Interpolation_CVPR_2024_paper.pdf"
        },
        {
            "type": "paper",
            "url": "https://ieeexplore.ieee.org/document/10658213"
        }
    ],
    "full_name": "",
    "additional_metadata": {
        "num_recordings": "9",
        "stereo": false
    },
    "bibtex": {
        "pages": "24977--24986",
        "year": 2024,
        "month": "jun",
        "author": "Yang, Yixin and Liang, Jinxiu and Yu, Bohan and Chen, Yan and Ren, Jimmy S. and Shi, Boxin",
        "publisher": "IEEE",
        "booktitle": "2024 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})",
        "urldate": "2024-12-15",
        "language": "en",
        "doi": "10.1109/CVPR52733.2024.02359",
        "url": "https://ieeexplore.ieee.org/document/10658213/",
        "isbn": "9798350353006",
        "copyright": "https://doi.org/10.15223/policy-029",
        "title": "Latency {Correction} for {Event}-{Guided} {Deblurring} and {Frame} {Interpolation}",
        "address": "Seattle, WA, USA",
        "type": "inproceedings",
        "key": "yang_latency_2024"
    },
    "referenced_papers": [
        {
            "doi": "10.1109/JSSC.2014.2342715",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ISCAS.1994.409266",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2019.01256",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TPAMI.2004.88",
            "source": "crossref"
        },
        {
            "doi": "10.3390/s21041137",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPRW53098.2021.00144",
            "source": "crossref"
        },
        {
            "doi": "10.1109/cvpr42600.2020.00338",
            "source": "crossref"
        },
        {
            "doi": "10.3389/fnins.2021.702765",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2011.2118490",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2007.914337",
            "source": "crossref"
        },
        {
            "doi": "10.1007/978-3-030-58598-3_41",
            "source": "crossref"
        },
        {
            "doi": "10.1117/1.OE.61.7.074103",
            "source": "crossref"
        },
        {
            "doi": "10.1117/12.2674435",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TPAMI.1981.4767166",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2019.00698",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TPAMI.2020.3036667",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2010.2085952",
            "source": "crossref"
        },
        {
            "doi": "10.21236/AD1211287",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2012.2230553",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICCV48922.2021.00449",
            "source": "crossref"
        },
        {
            "doi": "10.1007/978-3-031-19797-0_24",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR52729.2023.01730",
            "source": "crossref"
        },
        {
            "doi": "10.1007/978-3-031-20068-7_38",
            "source": "crossref"
        },
        {
            "doi": "10.1007/978-3-030-58601-0_10",
            "source": "crossref"
        },
        {
            "doi": "10.1109/iccv48922.2021.00258",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2018.00068",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR52688.2022.01724",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICCV51070.2023.00985",
            "source": "crossref"
        },
        {
            "doi": "10.1007/s11263-023-01754-5",
            "source": "crossref"
        },
        {
            "title": "Learning to Deblur and Generate High frame rate video with an event camera",
            "source": "crossref"
        },
        {
            "title": "inivation",
            "source": "crossref"
        },
        {
            "title": "Adam: A method for stochastic optimization",
            "source": "crossref"
        }
    ]
}
---


### Dataset Structure 
- Contains 9 recordings