---
{
    "name": "PKU-Spike-A",
    "aliases": [],
    "year": 2020,
    "modality": [
        "Vision"
    ],
    "sensors": [
        "Spike Camera"
    ],
    "other_sensors": [],
    "category": "Benchmarking, SNN Training Task, and SNN Training",
    "tags": [
        "Data Compression"
    ],
    "description": "Spike data compression",
    "dataset_properties": {
        "available_online": false,
        "has_real_data": false,
        "has_simulated_data": false,
        "has_ground_truth": false,
        "has_frames": false,
        "has_biases": false,
        "distribution_methods": [],
        "file_formats": [],
        "availability_comment": "Dataset available on request",
        "dataset_links": []
    },
    "paper": {
        "title": "Hybrid Coding of Spatiotemporal Spike Data for a Bio-Inspired Camera",
        "doi": "10.1109/TCSVT.2020.3032014",
        "authors": [
            "Lin Zhu",
            "Siwei Dong",
            "Tiejun Huang",
            "Yonghong Tian"
        ],
        "abstract": "Recently, a novel bio-inspired camera was developed by mimicking the retina fovea to continuously accumulate luminance intensity and then fire spikes once the dispatch threshold is reached. In contrast to the conventional frame-based cameras and the emerging dynamic vision sensors, this spike camera has shown remarkable advantages in capturing fast-moving scenes in a frame-free manner with full texture reconstruction capabilities. However, the ultra-high temporal resolution makes the transmission or storage of the output data of spike camera (referred to as spike data) quite difficult. To address the above challenges, we propose a unified lossy spike coding framework, which exploits the motion patterns hidden in the spike data distribution to design the motion-fidelity coding modes for the first time. We investigate the spatiotemporal distribution of spike data and propose an intensity-based measurement of the spike train distance. Then, the adaptive polyhedron partitioning is proposed to deal with the spike data with different motion characteristics. Finally, the intra-/inter-polyhedron prediction with spike-time and spike-rate modes, transform and multi-layer quantization are proposed and introduced into the codec. We also construct a PKU-Spike dataset captured by the spike camera to evaluate the compression performance. The experimental results on the dataset demonstrate that the proposed approach is effective in compressing such spike data while maintaining the visual fidelity especially for high-speed scenarios.",
        "open_access": false
    },
    "citation_counts": [
        {
            "source": "crossref",
            "count": 18,
            "updated": "2025-07-03T08:35:59.243293"
        },
        {
            "source": "scholar",
            "count": 25,
            "updated": "2025-07-03T08:35:58.839862"
        }
    ],
    "links": [
        {
            "type": "paper",
            "url": "https://ieeexplore.ieee.org/abstract/document/9229202"
        },
        {
            "type": "project_page",
            "url": "https://www.pkuml.org/resources/pku-spike.html"
        }
    ],
    "full_name": "",
    "additional_metadata": {
        "stereo": false
    },
    "bibtex": {
        "pages": "2837--2851",
        "year": 2021,
        "month": "jul",
        "author": "Zhu, Lin and Dong, Siwei and Huang, Tiejun and Tian, Yonghong",
        "journal": "IEEE Transactions on Circuits and Systems for Video Technology",
        "urldate": "2024-12-26",
        "number": "7",
        "language": "en",
        "doi": "10.1109/TCSVT.2020.3032014",
        "url": "https://ieeexplore.ieee.org/document/9229202/",
        "issn": "1051-8215, 1558-2205",
        "copyright": "https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html",
        "volume": "31",
        "title": "Hybrid {Coding} of {Spatiotemporal} {Spike} {Data} for a {Bio}-{Inspired} {Camera}",
        "type": "article",
        "key": "zhu_hybrid_2021"
    },
    "referenced_papers": [
        {
            "doi": "10.1109/MSP.2014.2371951",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TCSVT.2012.2221191",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TCSVT.2015.2450333",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TCSVT.2018.2802943",
            "source": "crossref"
        },
        {
            "doi": "10.1016/S0928-4257(97)81433-7",
            "source": "crossref"
        },
        {
            "doi": "10.1109/72.392256",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TCSVT.2003.815165",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TCSVT.2017.2751519",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TCSVT.2012.2223055",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TCSVT.2018.2885002",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ISSCC.1994.344657",
            "source": "crossref"
        },
        {
            "doi": "10.1109/PCS.2018.8456249",
            "source": "crossref"
        },
        {
            "doi": "10.1023/A:1008236112778",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2002.807412",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TBCAS.2013.2271382",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSEN.2018.2851063",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICME.2019.00248",
            "source": "crossref"
        },
        {
            "doi": "10.1109/DCC.2017.69",
            "source": "crossref"
        },
        {
            "doi": "10.1109/DCC.2019.00080",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2014.2342715",
            "source": "crossref"
        },
        {
            "doi": "10.1103/PhysRevE.62.8413",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JIOT.2018.2872984",
            "source": "crossref"
        },
        {
            "doi": "10.1162/089976604773135050",
            "source": "crossref"
        },
        {
            "doi": "10.1109/DSPWS.2006.265448",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2007.914337",
            "source": "crossref"
        },
        {
            "doi": "10.1037/h0037149",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2011.2118490",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ISCAS.2010.5537149",
            "source": "crossref"
        },
        {
            "doi": "10.1007/978-3-030-01258-8_46",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TPAMI.2020.3008413",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2018.00568",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ISCAS.2008.4541871",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TIP.2003.819861",
            "source": "crossref"
        },
        {
            "doi": "10.1007/BF02477711",
            "source": "crossref"
        },
        {
            "doi": "10.5594/M001518",
            "source": "crossref"
        },
        {
            "doi": "10.1109/DCC.2018.00020",
            "source": "crossref"
        },
        {
            "doi": "10.1007/s10339-005-0006-x",
            "source": "crossref"
        },
        {
            "doi": "10.1113/jphysiol.2003.053264",
            "source": "crossref"
        },
        {
            "title": "overview of the h.264/avc video coding standard",
            "source": "crossref"
        },
        {
            "title": "Retina-like visual image reconstruction via spiking neural model",
            "source": "crossref"
        },
        {
            "title": "Continuous-time intensity estimation using event cameras",
            "source": "crossref"
        },
        {
            "title": "Live demonstration: A $768\\times640$  pixels 200 MEPS dynamic vision sensor",
            "source": "crossref"
        },
        {
            "title": "A $640\\times480$  dynamic vision sensor with a $9~\\mu\\text{m}$  pixel and 300Meps address-event representation",
            "source": "crossref"
        }
    ]
}
---

### Dataset Structure
