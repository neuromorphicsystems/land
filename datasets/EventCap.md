---
{
    "name": "EventCap",
    "aliases": [],
    "year": 2020,
    "modalities": [
        "Vision"
    ],
    "sensors": [
        "DAVIS240"
    ],
    "other_sensors": [],
    "category": "Human-centric Recordings",
    "tags": [
        "Human Pose Recognition"
    ],
    "description": "Human pose estimation",
    "dataset_properties": {
        "available_online": false,
        "has_real_data": true,
        "has_simulated_data": false,
        "has_ground_truth": false,
        "has_frames": true,
        "has_biases": false,
        "distribution_methods": [],
        "file_formats": [],
        "availability_comment": "Dataset is stated as publicly available but no download link has been provided.",
        "dataset_links": []
    },
    "paper": {
        "title": "EventCap: Monocular 3D Capture of High-Speed Human Motions Using an Event Camera",
        "doi": "10.1109/CVPR42600.2020.00502",
        "authors": [
            "Lan Xu",
            "Weipeng Xu",
            "Vladislav Golyanik",
            "Marc Habermann",
            "Lu Fang",
            "Christian Theobalt"
        ],
        "abstract": "The high frame rate is a critical requirement for capturing fast human motions. In this setting, existing markerless image-based methods are constrained by the lighting requirement, the high data bandwidth and the consequent high computation overhead. In this paper, we propose EventCap \u2014 the first approach for 3D capturing of high-speed human motions using a single event camera. Our method combines model-based optimization and CNNbased human pose detection to capture high frequency motion details and to reduce the drifting in the tracking. As a result, we can capture fast motions at millisecond resolution with significantly higher data efficiency than using high frame rate videos. Experiments on our new event-based fast human motion dataset demonstrate the effectiveness and accuracy of our method, as well as its robustness to challenging lighting conditions.",
        "open_access": false
    },
    "citation_counts": [
        {
            "source": "crossref",
            "count": 83,
            "updated": "2025-07-02T14:13:33.424287"
        },
        {
            "source": "scholar",
            "count": 127,
            "updated": "2025-07-02T14:13:33.078809"
        }
    ],
    "links": [
        {
            "type": "preprint",
            "url": "https://arxiv.org/abs/1908.11505"
        },
        {
            "type": "paper",
            "url": "https://ieeexplore.ieee.org/document/9157340"
        }
    ],
    "full_name": "",
    "additional_metadata": {
        "num_recordings": "12",
        "num_subjects": "6"
    },
    "bibtex": {
        "pages": "4967--4977",
        "year": 2020,
        "month": "jun",
        "author": "Xu, Lan and Xu, Weipeng and Golyanik, Vladislav and Habermann, Marc and Fang, Lu and Theobalt, Christian",
        "publisher": "IEEE",
        "booktitle": "2020 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})",
        "urldate": "2024-04-30",
        "language": "en",
        "doi": "10.1109/CVPR42600.2020.00502",
        "url": "https://ieeexplore.ieee.org/document/9157340/",
        "shorttitle": "{EventCap}",
        "isbn": "978-1-72817-168-5",
        "copyright": "https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html",
        "title": "{EventCap}: {Monocular} {3D} {Capture} of {High}-{Speed} {Human} {Motions} {Using} an {Event} {Camera}",
        "address": "Seattle, WA, USA",
        "type": "inproceedings",
        "key": "xu_eventcap_2020"
    },
    "referenced_papers": [
        {
            "doi": "10.1023/A:1026531017760",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TVCG.2018.2812879",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TPAMI.2019.2928296",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2016.535",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2016.537",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2019.00698",
            "source": "crossref"
        },
        {
            "doi": "10.1109/3DV.2018.00062",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2007.914337",
            "source": "crossref"
        },
        {
            "doi": "10.1145/3272127.3275062",
            "source": "crossref"
        },
        {
            "doi": "10.1162/NECO_a_00720",
            "source": "crossref"
        },
        {
            "doi": "10.1109/BIOROB.2016.7523451",
            "source": "crossref"
        },
        {
            "doi": "10.1145/3072959.3073596",
            "source": "crossref"
        },
        {
            "doi": "10.1109/3DV.2017.00064",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2017.492",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICAR.2017.8023661",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2019.00463",
            "source": "crossref"
        },
        {
            "doi": "10.1145/2366145.2366207",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2018.00744",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TVCG.2019.2930691",
            "source": "crossref"
        },
        {
            "doi": "10.3390/s19204603",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TVCG.2017.2728660",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TPAMI.2019.2915229",
            "source": "crossref"
        },
        {
            "doi": "10.1145/3181973",
            "source": "crossref"
        },
        {
            "doi": "10.5244/C.27.45",
            "source": "crossref"
        },
        {
            "doi": "10.1145/3311970",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSTSP.2012.2196975",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2009.5206859",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICCVW.2017.100",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TPAMI.2013.248",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICCV.2015.381",
            "source": "crossref"
        },
        {
            "doi": "10.1007/s11263-009-0273-6",
            "source": "crossref"
        },
        {
            "doi": "10.1007/s11263-011-0493-4",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TNNLS.2015.2401834",
            "source": "crossref"
        },
        {
            "doi": "10.1007/978-3-642-12392-4_6",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICCV.2011.6126338",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2017.494",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2017.610",
            "source": "crossref"
        },
        {
            "doi": "10.1109/3DV.2016.58",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2017.139",
            "source": "crossref"
        },
        {
            "doi": "10.1016/0262-8856(92)90066-C",
            "source": "crossref"
        },
        {
            "doi": "10.1007/978-3-7091-6240-8_1",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2015.7299005",
            "source": "crossref"
        },
        {
            "doi": "10.3389/fnbot.2018.00004",
            "source": "crossref"
        },
        {
            "doi": "10.1007/s11263-008-0173-1",
            "source": "crossref"
        },
        {
            "doi": "10.1007/978-3-030-01258-8_46",
            "source": "crossref"
        },
        {
            "doi": "10.1109/3DV.2018.00074",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICCV.2011.6126356",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2013.464",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.1998.698581",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2017.143",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPRW.2019.00217",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2011.5995316",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICCV.2015.94",
            "source": "crossref"
        },
        {
            "doi": "10.1109/3DV.2016.25",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2018.00055",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2017.138",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPRW.2012.6238892",
            "source": "crossref"
        },
        {
            "title": "Deep Kinematic Pose Regression",
            "source": "crossref"
        },
        {
            "title": "SMPL: A skinned multiperson linear model",
            "source": "crossref"
        },
        {
            "title": "3D Human Pose Estimation from Monocular Images with Deep Convolutional Neural Network",
            "source": "crossref"
        },
        {
            "title": "Outdoor markerless motion capture with sparse handheld video cameras",
            "source": "crossref"
        },
        {
            "title": "Livecap: Real-time human performance capture from monocular video",
            "source": "crossref"
        },
        {
            "title": "Fusing 2D Uncertainty and 3D Cues for Monocular Body Pose Estimation",
            "source": "crossref"
        },
        {
            "title": "Structured Prediction of 3D Human Pose with Deep Neural Networks",
            "source": "crossref"
        },
        {
            "title": "Indirect deep structured learning for 3d human body shape and pose prediction",
            "source": "crossref"
        },
        {
            "title": "Event-based vision: A survey",
            "source": "crossref"
        },
        {
            "title": "Keep It SMPL: Automatic Estimation of 3D Human Pose and Shape from a Single Image",
            "source": "crossref"
        },
        {
            "title": "Neuromorphic event-based 3d pose estimation",
            "source": "crossref"
        },
        {
            "title": "Mocap Guided Data Augmentation for 3D Pose Estimation in the Wild",
            "source": "crossref"
        }
    ]
}
---

### Dataset Structure

- Contains 12 recordings of 6 subjects.
