---
{
    "name": "VETEX",
    "aliases": [],
    "year": 2025,
    "modality": [
        "Vision"
    ],
    "sensors": [
        "DAVIS346"
    ],
    "other_sensors": [
        "FLIR Duo R camera"
    ],
    "category": "Human-centric Recordings",
    "tags": [
        "Emotion Recognition",
        "Facial Expression",
        "Micro-expressions"
    ],
    "description": "Micro-expression recognition",
    "dataset_properties": {
        "available_online": false,
        "has_real_data": true,
        "has_simulated_data": false,
        "has_ground_truth": true,
        "has_frames": false,
        "has_biases": false,
        "distribution_methods": [],
        "file_formats": [],
        "availability_comment": "Dataset available on request",
        "dataset_links": []
    },
    "paper": {
        "title": "Beyond RGB: Tri-Modal Microexpression Recognition with\u00a0RGB, Thermal, and\u00a0Event Data",
        "doi": "10.1007/978-3-031-87660-8_23",
        "authors": [
            "Mira Adra",
            "Nelida Mirabet-Herranz",
            "Jean-Luc Dugelay"
        ],
        "abstract": "Facial Emotion recognition (FER) is an extensively studied computer vision task that aims at identifying and categorizing emotional expressions depicted on a human face, such as anger, fear, or happiness. Due to the subjective nature of feelings, deep learning models may struggle to learn implicit information about a person\u2019s emotions, leading to inaccuracies in existing methods. In this work, we aim to estimate microexpressions\u2014small facial movements that can indicate underlying feelings, as described in the Facial Action Coding System (FACS)\u2014from face videos, as these facial movements provide explicit information that is more easily perceivable by deep learning architectures. Furthermore, despite the evolution of FER technologies driven by advancements in neural network architectures and the exploration of new sensing technologies, there is a significant shortage of datasets that leverage these emerging modalities, which limits the progress of research in this field. In our study, we aim to explore and compare the feasibility of using different input data modalities, visible, thermal, and event, as training and testing data for a CNN baseline network by presenting a pioneering dataset that integrates these three modalities, each annotated with detailed Facial Action Units (FAUs) present in the FACS. Our proposed Visible, Event, and Thermal Face Dataset for Micro Expression Recognition (VETEX) containing 2506 face videos is available upon request.",
        "open_access": false
    },
    "citation_counts": [
        {
            "source": "crossref",
            "count": 0,
            "updated": "2025-06-22T12:44:33.884988"
        }
    ],
    "links": [
        {
            "type": "preprint",
            "url": "https://www.eurecom.fr/publication/7948/download/sec-publi-7948_1.pdf"
        },
        {
            "type": "paper",
            "url": "https://dl.acm.org/doi/abs/10.1007/978-3-031-87660-8_23"
        }
    ],
    "full_name": "Visible, Event, and Thermal Face Dataset for Micro Expression Recognition (VETEX)",
    "additional_metadata": {
        "num_subjects": "20",
        "num_classes": "7",
        "stereo": false
    },
    "bibtex": {
        "location": "Kolkata, India",
        "keywords": "Event Data, Thermal Spectra, Face Dataset, Microexpression, Facial Emotion Recognition, Tri-modal dataset",
        "numpages": "14",
        "pages": "311\u2013324",
        "booktitle": "Pattern Recognition. ICPR 2024 International Workshops and Challenges: Kolkata, India, December 1, 2024, Proceedings, Part II",
        "doi": "10.1007/978-3-031-87660-8_23",
        "url": "https://doi.org/10.1007/978-3-031-87660-8_23",
        "address": "Berlin, Heidelberg",
        "publisher": "Springer-Verlag",
        "isbn": "978-3-031-87659-2",
        "year": 2025,
        "title": "Beyond RGB: Tri-Modal Microexpression Recognition with&nbsp;RGB, Thermal, and&nbsp;Event Data",
        "author": "Adra, Mira and Mirabet-Herranz, Nelida and Dugelay, Jean-Luc",
        "type": "inproceedings",
        "key": "10.1007/978-3-031-87660-8_23"
    },
    "referenced_papers": [
        {
            "doi": "10.1109/AVSS61716.2024.10672575",
            "source": "crossref"
        },
        {
            "doi": "10.1145/3617233.3617235",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TII.2022.3195063",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPRW59228.2023.00432",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICMEW53276.2021.9455983",
            "source": "crossref"
        },
        {
            "doi": "10.1007/s00521-021-06012-8",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TPAMI.2016.2515606",
            "source": "crossref"
        },
        {
            "doi": "10.1109/BIOSIG55365.2022.9897039",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TPAMI.2020.3008413",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPRW53098.2021.00144",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICPR48806.2021.9412991",
            "source": "crossref"
        },
        {
            "doi": "10.1109/i2mtc.2018.8409768",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TIP.2020.2996086",
            "source": "crossref"
        },
        {
            "doi": "10.1109/taffc.2020.2981446",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPRW.2010.5543262",
            "source": "crossref"
        },
        {
            "doi": "10.1109/AFGR.1998.670949",
            "source": "crossref"
        },
        {
            "doi": "10.1109/BIOSIG58226.2023.10345997",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ACCESS.2023.3246047",
            "source": "crossref"
        },
        {
            "doi": "10.1007/978-3-319-39513-5_5",
            "source": "crossref"
        },
        {
            "doi": "10.1109/iccv.2015.510",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TMM.2010.2060716",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2019.00652",
            "source": "crossref"
        },
        {
            "doi": "10.1016/j.neucom.2021.02.047",
            "source": "crossref"
        },
        {
            "doi": "10.1016/j.imavis.2011.07.002",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TAFFC.2023.3341918",
            "source": "crossref"
        }
    ]
}
---

### Dataset Structure

- Contains data from 20 subjects.
- Contains 7 different micro-expressions, each recorded 6 times.
-
