---
{
    "name": "SL-ANIMALS-DVS",
    "aliases": [],
    "year": 2021,
    "modality": [
        "Vision"
    ],
    "sensors": [
        "S-DVS"
    ],
    "other_sensors": [],
    "category": "Human-centric Recordings",
    "tags": [
        "Sign Language",
        "Gesture Recognition"
    ],
    "description": "Sign Language Interpretation (Hand detection)",
    "dataset_properties": {
        "available_online": true,
        "has_real_data": true,
        "has_simulated_data": false,
        "has_ground_truth": true,
        "has_frames": false,
        "has_biases": false,
        "distribution_methods": [
            "Direct Download"
        ],
        "file_formats": [
            "aedat"
        ],
        "availability_comment": "",
        "dataset_links": [
            {
                "name": "Direct Download",
                "url": "http://www2.imse-cnm.csic.es/caviar/SL_Animals_Dataset/",
                "format": "aedat",
                "available": true
            }
        ],
        "size_gb": 0.749,
        "size_type": "Compressed"
    },
    "paper": {
        "title": "Introduction and Analysis of an Event-Based Sign Language Dataset",
        "doi": "10.1109/FG47880.2020.00069",
        "authors": [
            "Ajay Vasudevan",
            "Pablo Negri",
            "Bernabe Linares-Barranco",
            "Teresa Serrano-Gotarredona"
        ],
        "abstract": "Human gestures recognition is a complex visual recognition task where motion across time distinguishes the type of action. Automatic systems tackle this problem using complex machine learning architectures and training datasets. In recent years, the use and success of robust deep learning techniques was compatible with the availability of a great number of these sets. This paper presents SL-Animals-DVS, an event-based action dataset captured by a Dynamic Vision Sensor (DVS). The DVS records humans performing sign language gestures of various animals as a continuous spike \ufb02ow at very low latency. This is especially suited for sign language gestures which are usually made at very high speeds. We also benchmark the recognition performance on this data using two state-of-the-art Spiking Neural Networks (SNN) recognition systems. SNNs are naturally compatible to make use of the temporal information that is provided by the DVS where the information is encoded in the spike times. The dataset has about 1100 samples of 58 subjects performing 19 sign language gestures in isolation at different scenarios, providing a challenging evaluation platform for this emerging technology.",
        "open_access": false
    },
    "citation_counts": [
        {
            "source": "crossref",
            "count": 19,
            "updated": "2025-06-30T11:30:44.180340"
        },
        {
            "source": "scholar",
            "count": 33,
            "updated": "2025-06-30T11:30:43.855245"
        }
    ],
    "links": [
        {
            "type": "paper",
            "url": "https://ieeexplore.ieee.org/abstract/document/9320225/"
        },
        {
            "type": "project_page",
            "url": "http://www2.imse-cnm.csic.es/neuromorphs/index.php/SL-ANIMALS-DVS-Database"
        }
    ],
    "full_name": "",
    "additional_metadata": {
        "sl_type": "Spanish",
        "file_format": "aedat",
        "sensor_resolution": "128 x 128",
        "num_recordings": "1100",
        "num_subjects": "58",
        "num_classes": "19"
    },
    "bibtex": {
        "pages": "675--682",
        "year": 2020,
        "month": "nov",
        "author": "Vasudevan, Ajay and Negri, Pablo and Linares-Barranco, Bernabe and Serrano-Gotarredona, Teresa",
        "publisher": "IEEE",
        "booktitle": "2020 15th {IEEE} {International} {Conference} on {Automatic} {Face} and {Gesture} {Recognition} ({FG} 2020)",
        "urldate": "2024-04-13",
        "language": "en",
        "doi": "10.1109/FG47880.2020.00069",
        "url": "https://ieeexplore.ieee.org/document/9320225/",
        "isbn": "978-1-72813-079-8",
        "copyright": "https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html",
        "title": "Introduction and {Analysis} of an {Event}-{Based} {Sign} {Language} {Dataset}",
        "address": "Buenos Aires, Argentina",
        "type": "inproceedings",
        "key": "vasudevan_introduction_2020"
    },
    "referenced_papers": [
        {
            "doi": "10.1109/BDCloud-SocialCom-SustainCom.2016.76",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ISCAS.2017.8050403",
            "source": "crossref"
        },
        {
            "doi": "10.3758/s13428-016-0742-0",
            "source": "crossref"
        },
        {
            "doi": "10.3366/swc.2019.0258",
            "source": "crossref"
        },
        {
            "doi": "10.3389/fnins.2018.00331",
            "source": "crossref"
        },
        {
            "doi": "10.1007/s13042-017-0705-5",
            "source": "crossref"
        },
        {
            "doi": "10.1145/2897735",
            "source": "crossref"
        },
        {
            "doi": "10.1109/SCIS-ISIS.2018.00211",
            "source": "crossref"
        },
        {
            "doi": "10.1016/S1383-8121(01)80015-4",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2010.2085952",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TPAMI.2013.71",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2012.2230553",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ISQED.2016.7479186",
            "source": "crossref"
        },
        {
            "doi": "10.1016/S0893-6080(97)00011-7",
            "source": "crossref"
        },
        {
            "doi": "10.1002/admt.201800589",
            "source": "crossref"
        },
        {
            "doi": "10.1093/comjnl/bxy049",
            "source": "crossref"
        },
        {
            "doi": "10.1007/s13042-016-0512-4",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPRW.2016.100",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2017.781",
            "source": "crossref"
        },
        {
            "doi": "10.1016/j.neunet.2019.09.005",
            "source": "crossref"
        },
        {
            "title": "A million spiking-neuron integrated circuit with a scalable communication network and interface",
            "source": "crossref"
        },
        {
            "title": "The RVL-SLLL ASL Database",
            "source": "crossref"
        },
        {
            "title": "Towards a video corpus for signer-independent continuous sign language recognition",
            "source": "crossref"
        },
        {
            "title": "FLGR: Fixed Length Gists Representation Learning for RNN-HMM Hybrid-Based Neuromorphic Continuous Gesture Recognition",
            "source": "crossref"
        },
        {
            "title": "jAER Open Source Project",
            "source": "crossref"
        },
        {
            "title": "Extensions of the sign language recognition and translation corpus RWTH-PHOENIX-Wheather",
            "source": "crossref"
        },
        {
            "title": "Benchmark Databases for Video-Based Automatic Sign Language Recognition",
            "source": "crossref"
        },
        {
            "title": "Neuromorphic Spiking Neural Networks and Their Memristor-CMOS Hardware Implementations",
            "source": "crossref"
        },
        {
            "title": "An electronic dictionary of Danish Sign Language",
            "source": "crossref"
        },
        {
            "title": "SLAYER: Spike Layer Error Reassignment in Time",
            "source": "crossref"
        },
        {
            "title": "Evaluating deep models for dynamic brazilian sign language recognition",
            "source": "crossref"
        },
        {
            "title": "Spatio-Temporal Back-propagation for Training High-Performance Spiking Neural Networks",
            "source": "crossref"
        },
        {
            "title": "Large Scale Sign Language Interpretation",
            "source": "crossref"
        },
        {
            "title": "A framework for spiking neuron models: The spike response model",
            "source": "crossref"
        },
        {
            "title": "A 128*128 120db 15us latency asynchronous temporal contrast vision sensor",
            "source": "crossref"
        },
        {
            "title": "Event-based Gesture Recognition with Dynamic Background Suppression using Smartphone Computational Capabilities",
            "source": "crossref"
        },
        {
            "title": "Sign Language, International Encyclopedia of the Social And Behavioral Sciences",
            "source": "crossref"
        },
        {
            "title": "Comparison of SIFT and SURF methods for use on hand gesture recognition based on depth map",
            "source": "crossref"
        },
        {
            "title": "Is Neuromorphic MNIST neuromorphic? Analyzing discriminative power of neuromorphic datasets in the time domain",
            "source": "crossref"
        },
        {
            "title": "Chalearn looking at people challenge 2014: Dataset and results",
            "source": "crossref"
        }
    ]
}
---

### Dataset Structure

- Contains Spanish sign language of animals
- Stored as aedat files
- Recorded using an S-DVS with a resolution of 128 x 128
- Dataset contains 1100 recordings
- 58 subjects
- 19 different sign gestures
