---
{
    "name": "Jiang2024",
    "aliases": [],
    "year": 2024,
    "modality": [
        "Vision"
    ],
    "sensors": [
        "DAVIS346"
    ],
    "other_sensors": [],
    "category": "Filtering and De-noising",
    "subcategory": [
        "De-noising"
    ],
    "task": "Denoising Technique",
    "dataset_properties": {
        "available_online": false,
        "has_real_data": true,
        "has_simulated_data": false,
        "has_ground_truth": false,
        "has_frames": false,
        "has_biases": false,
        "distribution_methods": [],
        "file_formats": [],
        "availability_comment": "Dataset available on request",
        "dataset_links": []
    },
    "paper": {
        "title": "Event Stream Denoising Method Based on Spatio-Temporal Density and Time Sequence Analysis",
        "doi": "10.3390/s24206527",
        "authors": [
            "Haiyan Jiang",
            "Xiaoshuang Wang",
            "Wei Tang",
            "Qinghui Song",
            "Qingjun Song",
            "Wenchao Hao"
        ],
        "abstract": "An event camera is a neuromimetic sensor inspired by the human retinal imaging principle, which has the advantages of high dynamic range, high temporal resolution, and low power consumption. Due to the interference of hardware and software and other factors, the event stream output from the event camera usually contains a large amount of noise, and traditional denoising algorithms cannot be applied to the event stream. To better deal with different kinds of noise and enhance the robustness of the denoising algorithm, based on the spatio-temporal distribution characteristics of effective events and noise, an event stream noise reduction and visualization algorithm is proposed. The event stream enters fine filtering after filtering the BA noise based on spatio-temporal density. The fine filtering performs time sequence analysis on the event pixels and the neighboring pixels to filter out hot noise. The proposed visualization algorithm adaptively overlaps the events of the previous frame according to the event density difference to obtain clear and coherent event frames. We conducted denoising and visualization experiments on real scenes and public datasets, respectively, and the experiments show that our algorithm is effective in filtering noise and obtaining clear and coherent event frames under different event stream densities and noise backgrounds.",
        "open_access": true
    },
    "citation_counts": [
        {
            "source": "crossref",
            "count": 0,
            "updated": "2025-06-27T06:57:51.094973"
        },
        {
            "source": "scholar",
            "count": 2,
            "updated": "2025-06-27T06:57:50.089712"
        }
    ],
    "links": [
        {
            "type": "paper",
            "url": "https://www.mdpi.com/1424-8220/24/20/6527"
        }
    ],
    "full_name": "",
    "additional_metadata": {
        "stereo": false
    },
    "bibtex": {
        "pages": "6527",
        "year": 2024,
        "month": "oct",
        "author": "Jiang, Haiyan and Wang, Xiaoshuang and Tang, Wei and Song, Qinghui and Song, Qingjun and Hao, Wenchao",
        "journal": "Sensors",
        "urldate": "2024-12-15",
        "number": "20",
        "language": "en",
        "doi": "10.3390/s24206527",
        "url": "https://www.mdpi.com/1424-8220/24/20/6527",
        "issn": "1424-8220",
        "copyright": "https://creativecommons.org/licenses/by/4.0/",
        "volume": "24",
        "title": "Event {Stream} {Denoising} {Method} {Based} on {Spatio}-{Temporal} {Density} and {Time} {Sequence} {Analysis}",
        "type": "article",
        "key": "jiang_event_2024"
    },
    "referenced_papers": [
        {
            "doi": "10.1109/ISCAS.2010.5537149",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TPAMI.2020.3008413",
            "source": "crossref"
        },
        {
            "doi": "10.1109/WACV45572.2020.9093366",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2019.00698",
            "source": "crossref"
        },
        {
            "doi": "10.1007/978-3-030-20873-8_20",
            "source": "crossref"
        },
        {
            "doi": "10.1109/WACV.2016.7477561",
            "source": "crossref"
        },
        {
            "doi": "10.1007/s11263-017-1050-6",
            "source": "crossref"
        },
        {
            "doi": "10.1007/978-3-030-01246-5_15",
            "source": "crossref"
        },
        {
            "doi": "10.1016/j.neunet.2013.03.006",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICIP.2016.7532523",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TPAMI.2013.71",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2016.102",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPRW.2019.00216",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JPROC.2014.2347207",
            "source": "crossref"
        },
        {
            "doi": "10.5244/C.31.16",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2017.616",
            "source": "crossref"
        },
        {
            "doi": "10.1109/IROS.2018.8593805",
            "source": "crossref"
        },
        {
            "doi": "10.1109/LRA.2016.2645143",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICRA.2014.6906931",
            "source": "crossref"
        },
        {
            "doi": "10.1109/LRA.2018.2793357",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TMM.2020.2993957",
            "source": "crossref"
        },
        {
            "doi": "10.3390/app10062024",
            "source": "crossref"
        },
        {
            "doi": "10.1016/j.eswa.2024.124159",
            "source": "crossref"
        },
        {
            "doi": "10.3389/fnins.2018.00118",
            "source": "crossref"
        },
        {
            "doi": "10.1145/3503161.3548048",
            "source": "crossref"
        },
        {
            "doi": "10.1145/3177404.3177411",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ISCAS.2017.8050546",
            "source": "crossref"
        },
        {
            "doi": "10.3389/fnins.2015.00437",
            "source": "crossref"
        },
        {
            "doi": "10.3389/fnins.2017.00309",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2012.2230553",
            "source": "crossref"
        },
        {
            "doi": "10.1177/0278364917691115",
            "source": "crossref"
        },
        {
            "title": "Event-Based Vision: A Survey",
            "source": "crossref"
        },
        {
            "title": "EMVS: Event-Based Multi-View Stereo\u20143D Reconstruction with an Event Camera in Real-Time",
            "source": "crossref"
        },
        {
            "title": "Event-based 3D reconstruction from neuromorphic retinas",
            "source": "crossref"
        },
        {
            "title": "Mapping from frame-driven to framefree event-driven vision systems by low-rate rate coding and coincidence processing\u2013application to feedforward ConvNets",
            "source": "crossref"
        },
        {
            "title": "Asynchronous frameless event-based optical flow",
            "source": "crossref"
        },
        {
            "title": "Contour motion estimation for asynchronous event-driven cameras",
            "source": "crossref"
        },
        {
            "title": "EVO: A geometric approach to event-based 6-DOF parallel tracking and mapping in real-time",
            "source": "crossref"
        },
        {
            "title": "Ultimate SLAM? Combining Events, Images, and IMU for Robust Visual SLAM in HDR and High-Speed Scenarios",
            "source": "crossref"
        },
        {
            "title": "Adaptive Event Address Map Denoising for Event Cameras",
            "source": "crossref"
        },
        {
            "title": "Probabilistic undirected graph based denoising method for dynamic vision sensor",
            "source": "crossref"
        },
        {
            "title": "O(N)O(N)-Space Spatiotemporal Filter for Reducing Noise in Neuromorphic Vision Sensors",
            "source": "crossref"
        },
        {
            "title": "Audio-visual speech recognition based on regulated transformer and spatio-temporal fusion strategy for driver assistive systems",
            "source": "crossref"
        },
        {
            "title": "A 128 \u00d7 128 1.5% Contrast Sensitivity 0.9% FPN 3 \u00b5s Latency 4 mW Asynchronous Frame-Free Dynamic Vision Sensor Using Transimpedance Preamplifiers",
            "source": "crossref"
        },
        {
            "title": "The event-camera dataset and simulator: Event-based data for pose estimation, visual odometry, and SLAM",
            "source": "crossref"
        }
    ]
}
---


### Dataset Structure