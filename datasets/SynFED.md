---
{
    "name": "SynFED",
    "aliases": [],
    "year": 2022,
    "modality": [
        "Vision"
    ],
    "sensors": [
        "V2E"
    ],
    "other_sensors": [],
    "category": "Human-centric Recordings",
    "subcategory": [
        "Face Detection",
        "Face Identification"
    ],
    "task": "Face Identification",
    "dataset_properties": {
        "available_online": false,
        "has_real_data": false,
        "has_simulated_data": true,
        "has_ground_truth": false,
        "has_frames": true,
        "has_biases": false,
        "distribution_methods": [],
        "file_formats": [],
        "availability_comment": "Dataset link in Github not provided",
        "dataset_links": []
    },
    "paper": {
        "title": "Neuromorphic Event-based Face Identity Recognition",
        "doi": "10.1109/ICPR56361.2022.9956236",
        "authors": [
            "Goncalo Moreira",
            "Andre Graca",
            "Bruno Silva",
            "Pedro Martins",
            "Jorge Batista"
        ],
        "abstract": "Faces in motion contain rich information about a myriad of social cues, including identity. However, is still unknown how much information about a person\u2019s identity is conveyed by different kinds of facial movements and the precise role of facial motion as a cue for identity is still under debate. Open questions include how much information about identity is embedded in facial movements, and how efficiently a perceptual system extracts those cues toward identity. We address these questions by exploring the potential of Neuromorphic Vision Sensors to perform identity recognition through facial dynamics derived from speech and simultaneously validate how contributory facial motion is for human face identity categorization. As far as we know, this is the first work that evaluates the aptitude of the technology offered by neuromorphic cameras for completing the task of facial identity recognition. A one-stream inflated 3D convnet was used to evaluate the ability of different frame-based events encoding strategies in classifying identity through Short-Time Facial Motion Tokens (ST-FAMOTO). A consistent set of evaluations was conducted using two small datasets of individuals engaged in speech tasks, specifically text reading and speech-driven visual passcode. Results reported consistently consolidate the contribution of facial dynamics in the process of identity recognition and the usefulness of neuromorphic sensor devices in acquiring identity discriminatory facial micro-movements. Additionally, it is also proposed the first Neuromorphic Vision Dataset for Speech Induced Facial Dynamics (NVSFD Dataset), created in the scope of this work and available to facilitate future third-party investigation on the topic.",
        "open_access": false
    },
    "citation_counts": [
        {
            "source": "crossref",
            "count": 10,
            "updated": "2025-06-15T19:15:57.501012"
        },
        {
            "source": "scholar",
            "count": 11,
            "updated": "2025-06-15T19:15:57.338338"
        }
    ],
    "links": [
        {
            "type": "paper",
            "url": "https://ieeexplore.ieee.org/document/9956236"
        },
        {
            "type": "github_page",
            "url": "https://github.com/cv-projlab/NVFSD"
        }
    ],
    "full_name": "Neuromorphic Vision Dataset for Speech Induced Facial Dynamics",
    "additional_metadata": {
        "source_dataset": "S3DFM",
        "num_subjects": "30"
    },
    "bibtex": {
        "pages": "922--929",
        "year": 2022,
        "month": "aug",
        "author": "Moreira, Goncalo and Graca, Andre and Silva, Bruno and Martins, Pedro and Batista, Jorge",
        "publisher": "IEEE",
        "booktitle": "2022 26th {International} {Conference} on {Pattern} {Recognition} ({ICPR})",
        "urldate": "2024-09-21",
        "language": "en",
        "doi": "10.1109/ICPR56361.2022.9956236",
        "url": "https://ieeexplore.ieee.org/document/9956236/",
        "isbn": "978-1-66549-062-7",
        "copyright": "https://doi.org/10.15223/policy-029",
        "title": "Neuromorphic {Event}-based {Face} {Identity} {Recognition}",
        "address": "Montreal, QC, Canada",
        "type": "inproceedings",
        "key": "moreira_neuromorphic_2022"
    },
    "referenced_papers": [
        {
            "doi": "10.1109/CVPR.2017.502",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TNNLS.2014.2308551",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TAFFC.2015.2490070",
            "source": "crossref"
        },
        {
            "doi": "10.1016/j.neuropsychologia.2018.04.035",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICASSP.2010.5495071",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2017.781",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICPR48806.2021.9412991",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ISCAS45731.2020.9181247",
            "source": "crossref"
        },
        {
            "doi": "10.1109/WACV.2019.00199",
            "source": "crossref"
        },
        {
            "doi": "10.1016/j.specom.2017.07.001",
            "source": "crossref"
        },
        {
            "doi": "10.1007/978-3-319-14364-4_22",
            "source": "crossref"
        },
        {
            "doi": "10.1080/713756764",
            "source": "crossref"
        },
        {
            "doi": "10.1109/MSP.2017.2764116",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TIP.2019.2912358",
            "source": "crossref"
        },
        {
            "doi": "10.1007/978-3-030-01258-8_29",
            "source": "crossref"
        },
        {
            "doi": "10.1109/FG.2018.00098",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TIFS.2015.2406533",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TSMCA.2010.2041656",
            "source": "crossref"
        },
        {
            "doi": "10.1037/0022-3514.58.6.1004",
            "source": "crossref"
        },
        {
            "doi": "10.3758/BF03195788",
            "source": "crossref"
        },
        {
            "doi": "10.3389/fnins.2020.00275",
            "source": "crossref"
        },
        {
            "doi": "10.1007/978-3-319-13737-7_7",
            "source": "crossref"
        },
        {
            "doi": "10.1016/j.sigpro.2019.02.025",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TIFS.2018.2885276",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TPAMI.2007.1110",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2010.5539971",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TIP.2015.2412377",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ICIP.2016.7532909",
            "source": "crossref"
        },
        {
            "doi": "10.1109/BTAS.2016.7791172",
            "source": "crossref"
        },
        {
            "doi": "10.3389/fpsyg.2014.00633",
            "source": "crossref"
        },
        {
            "doi": "10.3389/fpsyg.2018.01355",
            "source": "crossref"
        },
        {
            "doi": "10.1016/S1364-6613(02)01908-3",
            "source": "crossref"
        },
        {
            "doi": "10.1038/srep34301",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TIFS.2007.902037",
            "source": "crossref"
        },
        {
            "doi": "10.1037/0096-1523.4.3.373",
            "source": "crossref"
        },
        {
            "doi": "10.3389/fnbot.2019.00038",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPRW53098.2021.00144",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TIP.2020.3023597",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2019.00401",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TNNLS.2013.2273537",
            "source": "crossref"
        },
        {
            "doi": "10.3389/fnins.2020.00587",
            "source": "crossref"
        },
        {
            "title": "Automatic 4d facial expression recognition via collaborative cross-domain dynamic image network",
            "source": "crossref"
        },
        {
            "title": "Visual speech recognition: aligning terminologies for better understanding",
            "source": "crossref"
        },
        {
            "title": "Deep pain: Exploiting long short-term memory networks for facial expression classification",
            "source": "crossref"
        },
        {
            "title": "Gender estimation based on smile-dynamics",
            "source": "crossref"
        },
        {
            "title": "Face liveness detection using dynamic texture",
            "source": "crossref"
        },
        {
            "title": "First order motion model for image animation",
            "source": "crossref"
        },
        {
            "title": "Event-based feature detection, recognition and classification",
            "source": "crossref"
        }
    ]
}
---

### Dataset Structure

- Contains data converted from the S3DFM dataset
- Contains data from 30 subjects

Contact `cv-projlab@isr.uc.pt`Â to receive the datasets passwords.
