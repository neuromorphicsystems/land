---
{
    "name": "E2D2",
    "aliases": [],
    "year": 2023,
    "modalities": [
        "Vision"
    ],
    "sensors": [
        "Prophesee Gen3"
    ],
    "other_sensors": [
        "Chameleon 3"
    ],
    "category": "Intensity Reconstruction, Optical Flow, and Frame Fusion",
    "tags": [
        "Beamsplitters",
        "Video Generation",
        "Video Interpolation"
    ],
    "description": "Continuous Color Video Decompression from Single Frames",
    "dataset_properties": {
        "available_online": false,
        "has_real_data": false,
        "has_simulated_data": true,
        "has_ground_truth": false,
        "has_frames": true,
        "has_biases": false,
        "distribution_methods": [],
        "file_formats": [],
        "availability_comment": "Dataset will be released upon publication",
        "dataset_links": []
    },
    "paper": {
        "title": "Event-based Continuous Color Video Decompression from Single Frames",
        "doi": "10.48550/arXiv.2312.00113",
        "authors": [
            "Ziyun Wang",
            "Friedhelm Hamann",
            "Kenneth Chaney",
            "Wen Jiang",
            "Guillermo Gallego",
            "Kostas Daniilidis"
        ],
        "abstract": "We present ContinuityCam, a novel approach to generate a continuous video from a single static RGB image, using an event camera. Conventional cameras struggle with high-speed motion capture due to bandwidth and dynamic range limitations. Event cameras are ideal sensors to solve this problem because they encode compressed change information at high temporal resolution. In this work, we propose a novel task called event-based continuous color video decompression, pairing single static color frames and events to reconstruct temporally continuous videos. Our approach combines continuous long-range motion modeling with a feature-plane-based synthesis neural integration model, enabling frame prediction at arbitrary times within the events. Our method does not rely on additional frames except for the initial image, increasing, thus, the robustness to sudden light changes, minimizing the prediction latency, and decreasing the bandwidth requirement. We introduce a novel single objective beamsplitter setup that acquires aligned images and events and a novel and challenging Event Extreme Decompression Dataset (E2D2) that tests the method in various lighting and motion profiles. We thoroughly evaluate our method through benchmarking reconstruction as well as various downstream tasks. Our approach significantly outperforms the event- and imagebased baselines in the proposed task. Please see our project website for code, data and additional results: https: //www.cis.upenn.edu/ \u0303ziyunw/continuity_ cam/.",
        "open_access": false
    },
    "citation_counts": [
        {
            "source": "scholar",
            "count": 8,
            "updated": "2025-07-02T14:36:19.378659"
        }
    ],
    "links": [
        {
            "type": "preprint",
            "url": "https://arxiv.org/abs/2312.00113"
        },
        {
            "type": "paper",
            "url": "https://arxiv.org/abs/2312.00113"
        },
        {
            "type": "project_page",
            "url": "https://www.cis.upenn.edu/~ziyunw/continuity_cam/"
        }
    ],
    "full_name": "Event Extreme Decompression Dataset (E2D2)",
    "additional_metadata": {
        "stereo": false
    },
    "bibtex": {
        "keywords": "Computer Science - Computer Vision and Pattern Recognition",
        "note": "arXiv:2312.00113 [cs]",
        "year": 2023,
        "month": "nov",
        "author": "Wang, Ziyun and Hamann, Friedhelm and Chaney, Kenneth and Jiang, Wen and Gallego, Guillermo and Daniilidis, Kostas",
        "publisher": "arXiv",
        "urldate": "2024-04-13",
        "language": "en",
        "doi": "10.48550/arXiv.2312.00113",
        "url": "http://arxiv.org/abs/2312.00113",
        "title": "Event-based {Continuous} {Color} {Video} {Decompression} from {Single} {Frames}",
        "type": "misc",
        "key": "wang_event-based_2023"
    }
}
---

### Dataset Structure
