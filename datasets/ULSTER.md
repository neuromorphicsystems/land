---
{
    "name": "ULSTER",
    "aliases": [
        "PRED16",
        "PRED18"
    ],
    "year": 2016,
    "modality": [
        "Vision"
    ],
    "sensors": [
        "DAVIS240"
    ],
    "other_sensors": [],
    "category": "Robotic and Moving Vehicle Datasets",
    "tags": [
        "Object Tracking"
    ],
    "description": "Object detection and tracking",
    "dataset_properties": {
        "available_online": true,
        "has_real_data": true,
        "has_simulated_data": false,
        "has_ground_truth": false,
        "has_frames": true,
        "has_biases": false,
        "distribution_methods": [
            "Direct Download"
        ],
        "file_formats": [
            "aedat"
        ],
        "availability_comment": "",
        "dataset_links": [
            {
                "name": "Direct Download",
                "url": "https://www.research-collection.ethz.ch/handle/20.500.11850/697579",
                "format": "aedat",
                "available": true,
                "doi": "10.3929/ethz-b-000697579"
            }
        ],
        "size_gb": 307.0,
        "size_type": "Compressed"
    },
    "paper": {
        "title": "Combined frame- and event-based detection and tracking",
        "doi": "10.1109/ISCAS.2016.7539103",
        "authors": [
            "Hongjie Liu",
            "Diederik Paul Moeys",
            "Gautham Das",
            "Daniel Neil",
            "Shih-Chii Liu",
            "Tobi Delbruck"
        ],
        "abstract": "This paper reports an object tracking algorithm for a moving platform using the dynamic and active-pixel vision sensor (DAVIS). It takes advantage of both the active pixel sensor (APS) frame and dynamic vision sensor (DVS) event outputs from the DAVIS. The tracking is performed in a three step-manner: regions of interest (ROIs) are generated by a cluster-based tracking using the DVS output, likely target locations are detected by using a convolutional neural network (CNN) on the APS output to classify the ROIs as foreground and background, and finally a particle filter infers the target location from the ROIs. Doing convolution only in the ROIs boosts the speed by a factor of 70 compared with full-frame convolutions for the 240\u00d7180 frame input from the DAVIS. The tracking accuracy on a predator and prey robot database reaches 90% with a cost of less than 20ms/frame in Matlab on a normal PC without using a GPU.",
        "open_access": false
    },
    "citation_counts": [
        {
            "source": "crossref",
            "count": 66,
            "updated": "2025-06-22T12:50:43.196830"
        },
        {
            "source": "scholar",
            "count": 115,
            "updated": "2025-06-22T12:50:42.370658"
        }
    ],
    "links": [
        {
            "type": "paper",
            "url": "https://ieeexplore.ieee.org/document/7539103"
        },
        {
            "type": "project_page",
            "url": "https://docs.google.com/document/d/e/2PACX-1vQ8HzlVv1ZzUEIfCUfUOUazXi__cacsCMU3LTqECrZk3-8nlyDCe2V29CHh20-cr42j8DrrMkFZGd14/pub"
        }
    ],
    "full_name": "",
    "additional_metadata": {
        "total_duration": "20 minutes"
    },
    "bibtex": {
        "pages": "2511--2514",
        "year": 2016,
        "month": "may",
        "author": "Liu, Hongjie and Moeys, Diederik Paul and Das, Gautham and Neil, Daniel and Liu, Shih-Chii and Delbruck, Tobi",
        "publisher": "IEEE",
        "booktitle": "2016 {IEEE} {International} {Symposium} on {Circuits} and {Systems} ({ISCAS})",
        "urldate": "2024-09-03",
        "language": "en",
        "doi": "10.1109/ISCAS.2016.7539103",
        "url": "https://ieeexplore.ieee.org/document/7539103",
        "isbn": "978-1-4799-5341-7",
        "title": "Combined frame- and event-based detection and tracking",
        "address": "Montr\u00e9al, QC, Canada",
        "type": "inproceedings",
        "key": "liu_combined_2016"
    },
    "referenced_papers": [
        {
            "doi": "10.1109/ISCAS.2015.7169170",
            "source": "crossref"
        },
        {
            "doi": "10.1111/j.1365-2818.2011.03565.x",
            "source": "crossref"
        },
        {
            "doi": "10.3389/fnins.2013.00223",
            "source": "crossref"
        },
        {
            "doi": "10.1162/NECO_a_00720",
            "source": "crossref"
        },
        {
            "doi": "10.1109/78.978396",
            "source": "crossref"
        },
        {
            "doi": "10.1109/CVPR.2013.312",
            "source": "crossref"
        },
        {
            "doi": "10.1109/TNN.2010.2066286",
            "source": "crossref"
        },
        {
            "doi": "10.1109/DSPWS.2006.265448",
            "source": "crossref"
        },
        {
            "doi": "10.1109/ISCAS.2009.5117867",
            "source": "crossref"
        },
        {
            "doi": "10.1007/s00348-011-1207-y",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2007.914337",
            "source": "crossref"
        },
        {
            "doi": "10.1109/JSSC.2014.2342715",
            "source": "crossref"
        },
        {
            "title": "jAER Open Source Project",
            "source": "crossref"
        },
        {
            "title": "rasmusbergpalm/DeepLearnToolbox",
            "source": "crossref"
        },
        {
            "title": "Human Tracking Using Convolutional Neural Networks",
            "source": "crossref"
        },
        {
            "title": "Frame-free dynamic digital vision",
            "source": "crossref"
        },
        {
            "title": "An Asynchronous Neuromorphic Event-Driven Visual Part-Based Shape Tracking",
            "source": "crossref"
        }
    ]
}
---

### Dataset Structure

- Dataset contains approximately 20 minutes of recordings
-
